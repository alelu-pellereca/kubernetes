
==> Audit <==
|--------------|---------------------------------------------------|----------|--------------------|---------|----------------------|----------------------|
|   Command    |                       Args                        | Profile  |        User        | Version |      Start Time      |       End Time       |
|--------------|---------------------------------------------------|----------|--------------------|---------|----------------------|----------------------|
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 14 Oct 24 16:24 CEST | 14 Oct 24 16:33 CEST |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 15 Oct 24 16:15 CEST | 15 Oct 24 16:15 CEST |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 15 Oct 24 16:21 CEST | 15 Oct 24 16:23 CEST |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 15 Oct 24 17:39 CEST | 15 Oct 24 17:39 CEST |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 15 Oct 24 17:39 CEST | 15 Oct 24 17:43 CEST |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 15 Oct 24 17:52 CEST | 15 Oct 24 17:52 CEST |
| service      | NodePort                                          | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 16 Oct 24 17:24 CEST |                      |
| service      | list                                              | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 16 Oct 24 17:25 CEST | 16 Oct 24 17:25 CEST |
| service      | hello                                             | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 16 Oct 24 17:25 CEST |                      |
| service      | hello                                             | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 16 Oct 24 17:27 CEST |                      |
| service      | hello                                             | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 16 Oct 24 17:44 CEST |                      |
| service      | hello                                             | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 16 Oct 24 18:17 CEST |                      |
| service      | hello                                             | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 16:34 CEST |                      |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 16:34 CEST |                      |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 16:51 CEST | 17 Oct 24 16:51 CEST |
| addons       | enable ingress                                    | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 16:52 CEST |                      |
| tunnel       |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 16:56 CEST |                      |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 16:59 CEST | 17 Oct 24 16:59 CEST |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:10 CEST |                      |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:17 CEST |                      |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:28 CEST | 17 Oct 24 17:28 CEST |
| tunnel       |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:45 CEST |                      |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:45 CEST |                      |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:56 CEST | 17 Oct 24 17:56 CEST |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:57 CEST | 17 Oct 24 17:57 CEST |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 17:57 CEST |                      |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 18:09 CEST | 17 Oct 24 18:09 CEST |
| delete       |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 18:15 CEST | 17 Oct 24 18:15 CEST |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 18:16 CEST | 17 Oct 24 18:19 CEST |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 18:38 CEST |                      |
| start        | --extra-config=apiserver.authorization-mode=RBAC* | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 18:47 CEST |                      |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 19:01 CEST |                      |
| update-check |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 19:16 CEST | 17 Oct 24 19:16 CEST |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 19:16 CEST |                      |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 19:17 CEST |                      |
| start        |                                                   | minikube | DESKTOP-1A2OVQD\pc | v1.34.0 | 17 Oct 24 19:18 CEST |                      |
|--------------|---------------------------------------------------|----------|--------------------|---------|----------------------|----------------------|


==> Last Start <==
Log file created at: 2024/10/17 19:18:00
Running on machine: DESKTOP-1A2OVQD
Binary: Built with gc go1.22.5 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1017 19:18:00.694946   13584 out.go:345] Setting OutFile to fd 96 ...
I1017 19:18:00.774741   13584 out.go:397] isatty.IsTerminal(96) = true
I1017 19:18:00.774741   13584 out.go:358] Setting ErrFile to fd 100...
I1017 19:18:00.774741   13584 out.go:397] isatty.IsTerminal(100) = true
I1017 19:18:00.839046   13584 out.go:352] Setting JSON to false
I1017 19:18:00.847322   13584 start.go:129] hostinfo: {"hostname":"DESKTOP-1A2OVQD","uptime":252583,"bootTime":1728932897,"procs":244,"os":"windows","platform":"Microsoft Windows 11 Home","platformFamily":"Standalone Workstation","platformVersion":"10.0.22621.4169 Build 22621.4169","kernelVersion":"10.0.22621.4169 Build 22621.4169","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"ac270e86-e6ac-4d56-8ddd-a3b430e10c17"}
W1017 19:18:00.847827   13584 start.go:137] gopshost.Virtualization returned error: not implemented yet
I1017 19:18:00.854191   13584 out.go:177] ðŸ˜„  minikube v1.34.0 on Microsoft Windows 11 Home 10.0.22621.4169 Build 22621.4169
I1017 19:18:00.858255   13584 notify.go:220] Checking for updates...
I1017 19:18:00.859479   13584 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.31.0
I1017 19:18:00.867192   13584 driver.go:394] Setting default libvirt URI to qemu:///system
I1017 19:18:01.090942   13584 docker.go:123] docker version: linux-27.2.0:Docker Desktop 4.34.2 (167172)
I1017 19:18:01.098189   13584 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1017 19:18:04.124279   13584 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (3.0260901s)
I1017 19:18:04.135760   13584 info.go:266] docker info: {ID:4845e8bf-ec5a-4920-8acf-5bcd0c2407ff Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:9 Driver:overlayfs DriverStatus:[[driver-type io.containerd.snapshotter.v1]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:53 OomKillDisable:true NGoroutines:79 SystemTime:2024-10-17 17:18:04.070141464 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:15 KernelVersion:5.15.153.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:3877244928 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[com.docker.desktop.address=npipe://\\.\pipe\docker_cli] ExperimentalBuild:false ServerVersion:27.2.0 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:8fc6bcff51318944179630522a095cc9dbf9f353 Expected:8fc6bcff51318944179630522a095cc9dbf9f353} RuncCommit:{ID:v1.1.13-0-g58aa920 Expected:v1.1.13-0-g58aa920} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.16.2-desktop.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.29.2-desktop.2] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container Vendor:Docker Inc. Version:0.0.34] map[Name:desktop Path:C:\Program Files\Docker\cli-plugins\docker-desktop.exe SchemaVersion:0.1.0 ShortDescription:Docker Desktop commands (Alpha) Vendor:Docker Inc. Version:v0.0.15] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.25] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.5] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.3.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.13.0]] Warnings:<nil>}}
I1017 19:18:04.137632   13584 out.go:177] âœ¨  Using the docker driver based on existing profile
I1017 19:18:04.141510   13584 start.go:297] selected driver: docker
I1017 19:18:04.141510   13584 start.go:901] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[{Component:apiserver Key:authorization-mode Value:RBAC*}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\pc:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I1017 19:18:04.141614   13584 start.go:912] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I1017 19:18:04.164096   13584 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I1017 19:18:04.678039   13584 info.go:266] docker info: {ID:4845e8bf-ec5a-4920-8acf-5bcd0c2407ff Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:9 Driver:overlayfs DriverStatus:[[driver-type io.containerd.snapshotter.v1]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:53 OomKillDisable:true NGoroutines:79 SystemTime:2024-10-17 17:18:04.641178444 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:15 KernelVersion:5.15.153.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:3877244928 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[com.docker.desktop.address=npipe://\\.\pipe\docker_cli] ExperimentalBuild:false ServerVersion:27.2.0 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:8fc6bcff51318944179630522a095cc9dbf9f353 Expected:8fc6bcff51318944179630522a095cc9dbf9f353} RuncCommit:{ID:v1.1.13-0-g58aa920 Expected:v1.1.13-0-g58aa920} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.16.2-desktop.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.29.2-desktop.2] map[Name:debug Path:C:\Program Files\Docker\cli-plugins\docker-debug.exe SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container Vendor:Docker Inc. Version:0.0.34] map[Name:desktop Path:C:\Program Files\Docker\cli-plugins\docker-desktop.exe SchemaVersion:0.1.0 ShortDescription:Docker Desktop commands (Alpha) Vendor:Docker Inc. Version:v0.0.15] map[Name:dev Path:C:\Program Files\Docker\cli-plugins\docker-dev.exe SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.25] map[Name:feedback Path:C:\Program Files\Docker\cli-plugins\docker-feedback.exe SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.5] map[Name:init Path:C:\Program Files\Docker\cli-plugins\docker-init.exe SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.3.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:C:\Program Files\Docker\cli-plugins\docker-scout.exe SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.13.0]] Warnings:<nil>}}
I1017 19:18:04.893343   13584 cni.go:84] Creating CNI manager for ""
I1017 19:18:04.893899   13584 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1017 19:18:04.894439   13584 start.go:340] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[{Component:apiserver Key:authorization-mode Value:RBAC*}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\pc:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I1017 19:18:04.895543   13584 out.go:177] ðŸ‘  Starting "minikube" primary control-plane node in "minikube" cluster
I1017 19:18:04.898375   13584 cache.go:121] Beginning downloading kic base image for docker with docker
I1017 19:18:04.899004   13584 out.go:177] ðŸšœ  Pulling base image v0.0.45 ...
I1017 19:18:04.902777   13584 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I1017 19:18:04.903293   13584 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local docker daemon
I1017 19:18:04.904540   13584 preload.go:146] Found local preload: C:\Users\pc\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4
I1017 19:18:04.905153   13584 cache.go:56] Caching tarball of preloaded images
I1017 19:18:04.906771   13584 preload.go:172] Found C:\Users\pc\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.31.0-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I1017 19:18:04.906771   13584 cache.go:59] Finished verifying existence of preloaded tar for v1.31.0 on docker
I1017 19:18:04.907306   13584 profile.go:143] Saving config to C:\Users\pc\.minikube\profiles\minikube\config.json ...
I1017 19:18:05.242275   13584 cache.go:149] Downloading gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 to local cache
I1017 19:18:05.249303   13584 localpath.go:151] windows sanitize: C:\Users\pc\.minikube\cache\kic\amd64\kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85.tar -> C:\Users\pc\.minikube\cache\kic\amd64\kicbase_v0.0.45@sha256_81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85.tar
I1017 19:18:05.249303   13584 localpath.go:151] windows sanitize: C:\Users\pc\.minikube\cache\kic\amd64\kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85.tar -> C:\Users\pc\.minikube\cache\kic\amd64\kicbase_v0.0.45@sha256_81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85.tar
I1017 19:18:05.249839   13584 image.go:63] Checking for gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local cache directory
I1017 19:18:05.251463   13584 image.go:66] Found gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 in local cache directory, skipping pull
I1017 19:18:05.252014   13584 image.go:135] gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 exists in cache, skipping pull
I1017 19:18:05.252014   13584 cache.go:152] successfully saved gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 as a tarball
I1017 19:18:05.252014   13584 cache.go:162] Loading gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 from local cache
I1017 19:18:05.252014   13584 localpath.go:151] windows sanitize: C:\Users\pc\.minikube\cache\kic\amd64\kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85.tar -> C:\Users\pc\.minikube\cache\kic\amd64\kicbase_v0.0.45@sha256_81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85.tar
I1017 19:19:01.194480   13584 cache.go:164] successfully loaded and using gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 from cached tarball
I1017 19:19:01.196018   13584 cache.go:194] Successfully downloaded all kic artifacts
I1017 19:19:01.214542   13584 start.go:360] acquireMachinesLock for minikube: {Name:mk18243a57b12ccb504dbdb8bd66ccbdfffd839e Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I1017 19:19:01.214542   13584 start.go:364] duration metric: took 0s to acquireMachinesLock for "minikube"
I1017 19:19:01.216223   13584 start.go:96] Skipping create...Using existing machine configuration
I1017 19:19:01.217200   13584 fix.go:54] fixHost starting: 
I1017 19:19:01.237948   13584 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1017 19:19:01.376183   13584 fix.go:112] recreateIfNeeded on minikube: state=Stopped err=<nil>
W1017 19:19:01.376732   13584 fix.go:138] unexpected machine state, will restart: <nil>
I1017 19:19:01.378005   13584 out.go:177] ðŸ”„  Restarting existing docker container for "minikube" ...
I1017 19:19:01.391859   13584 cli_runner.go:164] Run: docker start minikube
I1017 19:19:02.793701   13584 cli_runner.go:217] Completed: docker start minikube: (1.4014148s)
I1017 19:19:02.806253   13584 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1017 19:19:03.003992   13584 kic.go:430] container "minikube" state is running.
I1017 19:19:03.019814   13584 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1017 19:19:03.444138   13584 profile.go:143] Saving config to C:\Users\pc\.minikube\profiles\minikube\config.json ...
I1017 19:19:03.448938   13584 machine.go:93] provisionDockerMachine start ...
I1017 19:19:03.464585   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:03.591698   13584 main.go:141] libmachine: Using SSH client type: native
I1017 19:19:03.598440   13584 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x124c9c0] 0x124f5a0 <nil>  [] 0s} 127.0.0.1 57535 <nil> <nil>}
I1017 19:19:03.598440   13584 main.go:141] libmachine: About to run SSH command:
hostname
I1017 19:19:03.606093   13584 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: EOF
I1017 19:19:07.699985   13584 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I1017 19:19:07.739478   13584 ubuntu.go:169] provisioning hostname "minikube"
I1017 19:19:07.824162   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:07.961695   13584 main.go:141] libmachine: Using SSH client type: native
I1017 19:19:07.962201   13584 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x124c9c0] 0x124f5a0 <nil>  [] 0s} 127.0.0.1 57535 <nil> <nil>}
I1017 19:19:07.962201   13584 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I1017 19:19:10.490490   13584 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I1017 19:19:10.506670   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:10.855835   13584 main.go:141] libmachine: Using SSH client type: native
I1017 19:19:10.857876   13584 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x124c9c0] 0x124f5a0 <nil>  [] 0s} 127.0.0.1 57535 <nil> <nil>}
I1017 19:19:10.857876   13584 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I1017 19:19:11.096252   13584 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1017 19:19:11.097323   13584 ubuntu.go:175] set auth options {CertDir:C:\Users\pc\.minikube CaCertPath:C:\Users\pc\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\pc\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\pc\.minikube\machines\server.pem ServerKeyPath:C:\Users\pc\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\pc\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\pc\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\pc\.minikube}
I1017 19:19:11.097323   13584 ubuntu.go:177] setting up certificates
I1017 19:19:11.097323   13584 provision.go:84] configureAuth start
I1017 19:19:11.109341   13584 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1017 19:19:11.216444   13584 provision.go:143] copyHostCerts
I1017 19:19:11.220861   13584 exec_runner.go:144] found C:\Users\pc\.minikube/cert.pem, removing ...
I1017 19:19:11.221973   13584 exec_runner.go:203] rm: C:\Users\pc\.minikube\cert.pem
I1017 19:19:11.223039   13584 exec_runner.go:151] cp: C:\Users\pc\.minikube\certs\cert.pem --> C:\Users\pc\.minikube/cert.pem (1111 bytes)
I1017 19:19:11.226956   13584 exec_runner.go:144] found C:\Users\pc\.minikube/key.pem, removing ...
I1017 19:19:11.226956   13584 exec_runner.go:203] rm: C:\Users\pc\.minikube\key.pem
I1017 19:19:11.227635   13584 exec_runner.go:151] cp: C:\Users\pc\.minikube\certs\key.pem --> C:\Users\pc\.minikube/key.pem (1675 bytes)
I1017 19:19:11.231005   13584 exec_runner.go:144] found C:\Users\pc\.minikube/ca.pem, removing ...
I1017 19:19:11.231005   13584 exec_runner.go:203] rm: C:\Users\pc\.minikube\ca.pem
I1017 19:19:11.231514   13584 exec_runner.go:151] cp: C:\Users\pc\.minikube\certs\ca.pem --> C:\Users\pc\.minikube/ca.pem (1066 bytes)
I1017 19:19:11.233959   13584 provision.go:117] generating server cert: C:\Users\pc\.minikube\machines\server.pem ca-key=C:\Users\pc\.minikube\certs\ca.pem private-key=C:\Users\pc\.minikube\certs\ca-key.pem org=pc.minikube san=[127.0.0.1 192.168.49.2 localhost minikube]
I1017 19:19:11.655055   13584 provision.go:177] copyRemoteCerts
I1017 19:19:11.671385   13584 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I1017 19:19:11.677476   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:11.753808   13584 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:57535 SSHKeyPath:C:\Users\pc\.minikube\machines\minikube\id_rsa Username:docker}
I1017 19:19:11.878168   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1066 bytes)
I1017 19:19:11.948124   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\machines\server.pem --> /etc/docker/server.pem (1168 bytes)
I1017 19:19:12.008056   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I1017 19:19:12.061017   13584 provision.go:87] duration metric: took 961.8902ms to configureAuth
I1017 19:19:12.061017   13584 ubuntu.go:193] setting minikube options for container-runtime
I1017 19:19:12.063454   13584 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.31.0
I1017 19:19:12.068382   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:12.195639   13584 main.go:141] libmachine: Using SSH client type: native
I1017 19:19:12.196418   13584 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x124c9c0] 0x124f5a0 <nil>  [] 0s} 127.0.0.1 57535 <nil> <nil>}
I1017 19:19:12.196418   13584 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I1017 19:19:12.428044   13584 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I1017 19:19:12.428044   13584 ubuntu.go:71] root file system type: overlay
I1017 19:19:12.429760   13584 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I1017 19:19:12.437516   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:12.527568   13584 main.go:141] libmachine: Using SSH client type: native
I1017 19:19:12.528099   13584 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x124c9c0] 0x124f5a0 <nil>  [] 0s} 127.0.0.1 57535 <nil> <nil>}
I1017 19:19:12.528645   13584 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I1017 19:19:12.726875   13584 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I1017 19:19:12.735319   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:12.812337   13584 main.go:141] libmachine: Using SSH client type: native
I1017 19:19:12.812881   13584 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x124c9c0] 0x124f5a0 <nil>  [] 0s} 127.0.0.1 57535 <nil> <nil>}
I1017 19:19:12.812881   13584 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I1017 19:19:13.044895   13584 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I1017 19:19:13.044979   13584 machine.go:96] duration metric: took 9.5959566s to provisionDockerMachine
I1017 19:19:13.045600   13584 start.go:293] postStartSetup for "minikube" (driver="docker")
I1017 19:19:13.045600   13584 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I1017 19:19:13.063537   13584 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I1017 19:19:13.067489   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:13.136768   13584 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:57535 SSHKeyPath:C:\Users\pc\.minikube\machines\minikube\id_rsa Username:docker}
I1017 19:19:13.292424   13584 ssh_runner.go:195] Run: cat /etc/os-release
I1017 19:19:13.301403   13584 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I1017 19:19:13.301403   13584 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I1017 19:19:13.301403   13584 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I1017 19:19:13.301403   13584 info.go:137] Remote host: Ubuntu 22.04.4 LTS
I1017 19:19:13.301403   13584 filesync.go:126] Scanning C:\Users\pc\.minikube\addons for local assets ...
I1017 19:19:13.301955   13584 filesync.go:126] Scanning C:\Users\pc\.minikube\files for local assets ...
I1017 19:19:13.301955   13584 start.go:296] duration metric: took 256.3548ms for postStartSetup
I1017 19:19:13.315610   13584 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I1017 19:19:13.319832   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:13.392591   13584 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:57535 SSHKeyPath:C:\Users\pc\.minikube\machines\minikube\id_rsa Username:docker}
I1017 19:19:13.526760   13584 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I1017 19:19:13.538275   13584 fix.go:56] duration metric: took 12.3205477s for fixHost
I1017 19:19:13.538275   13584 start.go:83] releasing machines lock for "minikube", held for 12.3237336s
I1017 19:19:13.542903   13584 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I1017 19:19:13.618619   13584 ssh_runner.go:195] Run: curl.exe -sS -m 2 https://registry.k8s.io/
I1017 19:19:13.624013   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:13.629131   13584 ssh_runner.go:195] Run: cat /version.json
I1017 19:19:13.635174   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:13.707492   13584 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:57535 SSHKeyPath:C:\Users\pc\.minikube\machines\minikube\id_rsa Username:docker}
I1017 19:19:13.724102   13584 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:57535 SSHKeyPath:C:\Users\pc\.minikube\machines\minikube\id_rsa Username:docker}
W1017 19:19:13.851102   13584 start.go:867] [curl.exe -sS -m 2 https://registry.k8s.io/] failed: curl.exe -sS -m 2 https://registry.k8s.io/: Process exited with status 127
stdout:

stderr:
bash: line 1: curl.exe: command not found
I1017 19:19:13.885603   13584 ssh_runner.go:195] Run: systemctl --version
I1017 19:19:13.920090   13584 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I1017 19:19:13.943243   13584 ssh_runner.go:195] Run: sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
W1017 19:19:13.967316   13584 start.go:439] unable to name loopback interface in configureRuntimes: unable to patch loopback cni config "/etc/cni/net.d/*loopback.conf*": sudo find \etc\cni\net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;: Process exited with status 1
stdout:

stderr:
find: '\\etc\\cni\\net.d': No such file or directory
I1017 19:19:13.981009   13584 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%p, " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I1017 19:19:13.999652   13584 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I1017 19:19:13.999652   13584 start.go:495] detecting cgroup driver to use...
I1017 19:19:13.999652   13584 detect.go:187] detected "cgroupfs" cgroup driver on host os
I1017 19:19:14.002425   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I1017 19:19:14.051250   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.10"|' /etc/containerd/config.toml"
W1017 19:19:14.073015   13584 out.go:270] â—  Failing to connect to https://registry.k8s.io/ from inside the minikube container
W1017 19:19:14.073523   13584 out.go:270] ðŸ’¡  To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
I1017 19:19:14.086227   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I1017 19:19:14.121500   13584 containerd.go:146] configuring containerd to use "cgroupfs" as cgroup driver...
I1017 19:19:14.141470   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I1017 19:19:14.178410   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1017 19:19:14.210275   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I1017 19:19:14.243442   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I1017 19:19:14.280488   13584 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I1017 19:19:14.322474   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I1017 19:19:14.359198   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I1017 19:19:14.396593   13584 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I1017 19:19:14.433110   13584 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I1017 19:19:14.468165   13584 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I1017 19:19:14.496926   13584 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 19:19:14.756419   13584 ssh_runner.go:195] Run: sudo systemctl restart containerd
I1017 19:19:15.016048   13584 start.go:495] detecting cgroup driver to use...
I1017 19:19:15.016048   13584 detect.go:187] detected "cgroupfs" cgroup driver on host os
I1017 19:19:15.033394   13584 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I1017 19:19:15.062949   13584 cruntime.go:279] skipping containerd shutdown because we are bound to it
I1017 19:19:15.083286   13584 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I1017 19:19:15.116306   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I1017 19:19:15.173143   13584 ssh_runner.go:195] Run: which cri-dockerd
I1017 19:19:15.200552   13584 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I1017 19:19:15.224795   13584 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (190 bytes)
I1017 19:19:15.302592   13584 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I1017 19:19:15.532568   13584 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I1017 19:19:15.728423   13584 docker.go:574] configuring docker to use "cgroupfs" as cgroup driver...
I1017 19:19:15.728932   13584 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I1017 19:19:15.785143   13584 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 19:19:15.990374   13584 ssh_runner.go:195] Run: sudo systemctl restart docker
I1017 19:19:16.679732   13584 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I1017 19:19:16.715589   13584 ssh_runner.go:195] Run: sudo systemctl stop cri-docker.socket
I1017 19:19:16.760080   13584 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I1017 19:19:16.809791   13584 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I1017 19:19:17.068832   13584 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I1017 19:19:17.287700   13584 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 19:19:17.477946   13584 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I1017 19:19:17.516036   13584 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I1017 19:19:17.552358   13584 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 19:19:17.723285   13584 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I1017 19:19:18.346749   13584 start.go:542] Will wait 60s for socket path /var/run/cri-dockerd.sock
I1017 19:19:18.366897   13584 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I1017 19:19:18.376325   13584 start.go:563] Will wait 60s for crictl version
I1017 19:19:18.390020   13584 ssh_runner.go:195] Run: which crictl
I1017 19:19:18.413370   13584 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I1017 19:19:18.747214   13584 start.go:579] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  27.2.0
RuntimeApiVersion:  v1
I1017 19:19:18.752290   13584 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1017 19:19:19.017308   13584 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I1017 19:19:19.063142   13584 out.go:235] ðŸ³  Preparing Kubernetes v1.31.0 on Docker 27.2.0 ...
I1017 19:19:19.069121   13584 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I1017 19:19:19.349692   13584 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I1017 19:19:19.365065   13584 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I1017 19:19:19.375079   13584 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.254	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1017 19:19:19.407240   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1017 19:19:19.488677   13584 out.go:177]     â–ª apiserver.authorization-mode=RBAC*
I1017 19:19:19.492531   13584 kubeadm.go:883] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[{Component:apiserver Key:authorization-mode Value:RBAC*}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\pc:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I1017 19:19:19.493059   13584 preload.go:131] Checking if preload exists for k8s version v1.31.0 and runtime docker
I1017 19:19:19.500896   13584 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1017 19:19:19.542197   13584 docker.go:685] Got preloaded images: -- stdout --
registry.k8s.io/kube-controller-manager:v1.31.0
registry.k8s.io/kube-scheduler:v1.31.0
registry.k8s.io/kube-apiserver:v1.31.0
registry.k8s.io/kube-proxy:v1.31.0
<none>:<none>
registry.k8s.io/etcd:3.5.15-0
registry.k8s.io/pause:3.10
registry.k8s.io/coredns/coredns:v1.11.1
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I1017 19:19:19.542197   13584 docker.go:615] Images already preloaded, skipping extraction
I1017 19:19:19.550449   13584 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I1017 19:19:19.587365   13584 docker.go:685] Got preloaded images: -- stdout --
registry.k8s.io/kube-controller-manager:v1.31.0
registry.k8s.io/kube-apiserver:v1.31.0
registry.k8s.io/kube-scheduler:v1.31.0
registry.k8s.io/kube-proxy:v1.31.0
<none>:<none>
registry.k8s.io/etcd:3.5.15-0
registry.k8s.io/pause:3.10
registry.k8s.io/coredns/coredns:v1.11.1
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I1017 19:19:19.588497   13584 cache_images.go:84] Images are preloaded, skipping loading
I1017 19:19:19.588497   13584 kubeadm.go:934] updating node { 192.168.49.2 8443 v1.31.0 docker true true} ...
I1017 19:19:19.589578   13584 kubeadm.go:946] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.31.0/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[{Component:apiserver Key:authorization-mode Value:RBAC*}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I1017 19:19:19.595110   13584 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I1017 19:19:20.214685   13584 cni.go:84] Creating CNI manager for ""
I1017 19:19:20.214685   13584 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I1017 19:19:20.215275   13584 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I1017 19:19:20.215275   13584 kubeadm.go:181] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.31.0 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[authorization-mode:RBAC* enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I1017 19:19:20.215800   13584 kubeadm.go:187] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    authorization-mode: "RBAC*"
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.31.0
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I1017 19:19:20.228355   13584 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.31.0
I1017 19:19:20.252485   13584 binaries.go:44] Found k8s binaries, skipping transfer
I1017 19:19:20.266986   13584 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I1017 19:19:20.286966   13584 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (307 bytes)
I1017 19:19:20.321087   13584 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I1017 19:19:20.356307   13584 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2182 bytes)
I1017 19:19:20.403647   13584 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I1017 19:19:20.412653   13584 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I1017 19:19:20.447011   13584 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 19:19:20.659269   13584 ssh_runner.go:195] Run: sudo systemctl start kubelet
I1017 19:19:20.687639   13584 certs.go:68] Setting up C:\Users\pc\.minikube\profiles\minikube for IP: 192.168.49.2
I1017 19:19:20.687639   13584 certs.go:194] generating shared ca certs ...
I1017 19:19:20.688146   13584 certs.go:226] acquiring lock for ca certs: {Name:mkf32f0a87c16b817118175f388502470b325c9c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 19:19:20.689880   13584 certs.go:235] skipping valid "minikubeCA" ca cert: C:\Users\pc\.minikube\ca.key
I1017 19:19:20.690975   13584 certs.go:235] skipping valid "proxyClientCA" ca cert: C:\Users\pc\.minikube\proxy-client-ca.key
I1017 19:19:20.692078   13584 certs.go:256] generating profile certs ...
I1017 19:19:20.694636   13584 certs.go:359] skipping valid signed profile cert regeneration for "minikube-user": C:\Users\pc\.minikube\profiles\minikube\client.key
I1017 19:19:20.695737   13584 certs.go:359] skipping valid signed profile cert regeneration for "minikube": C:\Users\pc\.minikube\profiles\minikube\apiserver.key.7fb57e3c
I1017 19:19:20.697772   13584 certs.go:359] skipping valid signed profile cert regeneration for "aggregator": C:\Users\pc\.minikube\profiles\minikube\proxy-client.key
I1017 19:19:20.699290   13584 certs.go:484] found cert: C:\Users\pc\.minikube\certs\ca-key.pem (1675 bytes)
I1017 19:19:20.699290   13584 certs.go:484] found cert: C:\Users\pc\.minikube\certs\ca.pem (1066 bytes)
I1017 19:19:20.699799   13584 certs.go:484] found cert: C:\Users\pc\.minikube\certs\cert.pem (1111 bytes)
I1017 19:19:20.699799   13584 certs.go:484] found cert: C:\Users\pc\.minikube\certs\key.pem (1675 bytes)
I1017 19:19:20.721838   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I1017 19:19:20.772441   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I1017 19:19:20.821811   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I1017 19:19:20.872167   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I1017 19:19:20.919916   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1411 bytes)
I1017 19:19:20.970212   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I1017 19:19:21.037961   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I1017 19:19:21.123412   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I1017 19:19:21.181010   13584 ssh_runner.go:362] scp C:\Users\pc\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I1017 19:19:21.233328   13584 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (740 bytes)
I1017 19:19:21.290463   13584 ssh_runner.go:195] Run: openssl version
I1017 19:19:21.332808   13584 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I1017 19:19:21.389448   13584 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I1017 19:19:21.399047   13584 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Oct 14 14:33 /usr/share/ca-certificates/minikubeCA.pem
I1017 19:19:21.416989   13584 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I1017 19:19:21.451882   13584 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I1017 19:19:21.496507   13584 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I1017 19:19:21.523400   13584 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I1017 19:19:21.585916   13584 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I1017 19:19:21.668985   13584 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I1017 19:19:21.717000   13584 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I1017 19:19:21.803573   13584 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I1017 19:19:21.872552   13584 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I1017 19:19:21.908446   13584 kubeadm.go:392] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.45@sha256:81df288595202a317b1a4dc2506ca2e4ed5f22373c19a441b88cfbf4b9867c85 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.31.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[{Component:apiserver Key:authorization-mode Value:RBAC*}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\pc:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I1017 19:19:21.922350   13584 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1017 19:19:22.138098   13584 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I1017 19:19:22.165392   13584 kubeadm.go:408] found existing configuration files, will attempt cluster restart
I1017 19:19:22.165916   13584 kubeadm.go:593] restartPrimaryControlPlane start ...
I1017 19:19:22.185064   13584 ssh_runner.go:195] Run: sudo test -d /data/minikube
I1017 19:19:22.205236   13584 kubeadm.go:130] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I1017 19:19:22.212659   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1017 19:19:22.348354   13584 kubeconfig.go:125] found "minikube" server: "https://127.0.0.1:63507"
I1017 19:19:22.348991   13584 kubeconfig.go:47] verify endpoint returned: got: 127.0.0.1:63507, want: 127.0.0.1:57534
I1017 19:19:22.349626   13584 kubeconfig.go:62] C:\Users\pc\.kube\config needs updating (will repair): [kubeconfig needs server address update]
I1017 19:19:22.351314   13584 lock.go:35] WriteFile acquiring C:\Users\pc\.kube\config: {Name:mkfbf17f2be471acca4d9df92a8d53d66c50c230 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 19:19:22.459572   13584 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I1017 19:19:22.487498   13584 kubeadm.go:630] The running cluster does not require reconfiguration: 127.0.0.1
I1017 19:19:22.487498   13584 kubeadm.go:597] duration metric: took 321.5823ms to restartPrimaryControlPlane
I1017 19:19:22.489008   13584 kubeadm.go:394] duration metric: took 580.5621ms to StartCluster
I1017 19:19:22.489008   13584 settings.go:142] acquiring lock: {Name:mka79bb165bd544a134f50c921453a6b9aa2659d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 19:19:22.489008   13584 settings.go:150] Updating kubeconfig:  C:\Users\pc\.kube\config
I1017 19:19:22.490239   13584 lock.go:35] WriteFile acquiring C:\Users\pc\.kube\config: {Name:mkfbf17f2be471acca4d9df92a8d53d66c50c230 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1017 19:19:22.492696   13584 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.31.0
I1017 19:19:22.493205   13584 addons.go:507] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volcano:false volumesnapshots:false yakd:false]
I1017 19:19:22.493483   13584 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I1017 19:19:22.493483   13584 addons.go:69] Setting default-storageclass=true in profile "minikube"
I1017 19:19:22.493483   13584 start.go:235] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.31.0 ContainerRuntime:docker ControlPlane:true Worker:true}
I1017 19:19:22.493990   13584 addons.go:234] Setting addon storage-provisioner=true in "minikube"
W1017 19:19:22.493990   13584 addons.go:243] addon storage-provisioner should already be in state true
I1017 19:19:22.494082   13584 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I1017 19:19:22.494589   13584 host.go:66] Checking if "minikube" exists ...
I1017 19:19:22.494589   13584 out.go:177] ðŸ”Ž  Verifying Kubernetes components...
I1017 19:19:22.517288   13584 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1017 19:19:22.518283   13584 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1017 19:19:22.582032   13584 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I1017 19:19:22.702481   13584 addons.go:234] Setting addon default-storageclass=true in "minikube"
W1017 19:19:22.702481   13584 addons.go:243] addon default-storageclass should already be in state true
I1017 19:19:22.702989   13584 host.go:66] Checking if "minikube" exists ...
I1017 19:19:22.717362   13584 out.go:177]     â–ª Using image gcr.io/k8s-minikube/storage-provisioner:v5
I1017 19:19:22.718908   13584 addons.go:431] installing /etc/kubernetes/addons/storage-provisioner.yaml
I1017 19:19:22.718908   13584 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I1017 19:19:22.721141   13584 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I1017 19:19:22.727789   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:22.888763   13584 addons.go:431] installing /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:22.888763   13584 ssh_runner.go:362] scp storageclass/storageclass.yaml --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I1017 19:19:22.895451   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I1017 19:19:22.916289   13584 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:57535 SSHKeyPath:C:\Users\pc\.minikube\machines\minikube\id_rsa Username:docker}
I1017 19:19:23.002754   13584 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:57535 SSHKeyPath:C:\Users\pc\.minikube\machines\minikube\id_rsa Username:docker}
I1017 19:19:23.275303   13584 ssh_runner.go:195] Run: sudo systemctl start kubelet
I1017 19:19:23.457089   13584 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I1017 19:19:23.503946   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I1017 19:19:23.695020   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:23.966955   13584 api_server.go:52] waiting for apiserver process to appear ...
I1017 19:19:24.028505   13584 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 19:19:25.480138   13584 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (1.9761925s)
I1017 19:19:25.480138   13584 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (1.7851178s)
W1017 19:19:25.480138   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W1017 19:19:25.480138   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:25.480138   13584 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (1.4516332s)
I1017 19:19:25.481245   13584 retry.go:31] will retry after 225.701684ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:25.481245   13584 retry.go:31] will retry after 130.539142ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:25.537642   13584 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1017 19:19:25.618621   13584 api_server.go:72] duration metric: took 3.1251384s to wait for apiserver process to appear ...
I1017 19:19:25.618621   13584 api_server.go:88] waiting for apiserver healthz status ...
I1017 19:19:25.623192   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:25.629887   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:25.636386   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:25.747996   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:19:26.034324   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:26.034324   13584 retry.go:31] will retry after 502.761764ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W1017 19:19:26.108493   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:26.108493   13584 retry.go:31] will retry after 458.766035ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:26.125421   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:26.133927   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:26.572422   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:26.599660   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I1017 19:19:26.620493   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:26.630784   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
W1017 19:19:27.078918   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:27.078918   13584 retry.go:31] will retry after 747.805402ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:27.122968   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:27.126300   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
W1017 19:19:27.156294   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:27.156294   13584 retry.go:31] will retry after 501.760919ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:27.618783   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:27.628075   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:27.693675   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I1017 19:19:27.864976   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:28.131513   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:28.139362   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
W1017 19:19:28.177778   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:28.177778   13584 retry.go:31] will retry after 1.028488945s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W1017 19:19:28.304698   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:28.304698   13584 retry.go:31] will retry after 729.211412ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:28.627129   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:28.636006   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:29.066042   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:29.124869   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:29.133807   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:29.232125   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:19:29.266477   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:29.266477   13584 retry.go:31] will retry after 706.154519ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W1017 19:19:29.386605   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:29.386605   13584 retry.go:31] will retry after 1.062873229s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:29.623427   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:29.626406   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:30.002071   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:30.134765   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:30.139212   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
W1017 19:19:30.142936   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:30.142936   13584 retry.go:31] will retry after 2.748406071s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:30.479524   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:19:30.584932   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:30.584932   13584 retry.go:31] will retry after 1.334312205s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:30.627755   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:30.635000   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:31.127512   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:31.132604   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:31.625668   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:31.629075   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:31.939904   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:19:32.106548   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:32.106548   13584 retry.go:31] will retry after 3.25091885s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:32.121866   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:32.124609   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:32.620139   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:32.624842   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:32.950065   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W1017 19:19:33.050681   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:33.050681   13584 retry.go:31] will retry after 1.459737274s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:33.133569   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:33.143211   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:33.630561   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:33.640636   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:34.128741   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:34.131721   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:34.549493   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:19:34.625945   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:34.628612   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
W1017 19:19:34.645781   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:34.645781   13584 retry.go:31] will retry after 5.430649132s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:35.127104   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:35.145021   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:35.374519   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:19:35.475144   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:35.475692   13584 retry.go:31] will retry after 5.477393329s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:35.620772   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:35.633411   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:36.131898   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:36.137405   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:36.627171   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:36.636100   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:37.124180   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:37.129270   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:37.622990   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:37.635114   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:38.122389   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:38.133467   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:38.634287   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:38.646273   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:39.120875   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:39.134935   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:39.618897   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:39.622492   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:40.132126   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:40.139410   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:40.150815   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W1017 19:19:40.245573   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:40.245573   13584 retry.go:31] will retry after 5.552565546s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:40.630184   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:40.633680   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:40.972440   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:19:41.081342   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:41.081342   13584 retry.go:31] will retry after 7.888073867s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:41.127828   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:41.131409   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:41.620716   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:41.626441   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:42.129842   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:42.134133   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:42.632287   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:42.644935   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:43.129064   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:43.143492   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:43.630224   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:43.641355   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:44.130432   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:44.146320   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:44.626737   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:44.629864   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:45.119288   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:45.122396   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:45.632386   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:45.636823   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:45.840445   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W1017 19:19:45.932966   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:45.932966   13584 retry.go:31] will retry after 6.435744682s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:46.129195   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:46.139039   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:46.627803   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:46.639285   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:47.125230   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:47.130081   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:47.625736   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:47.639860   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:48.122408   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:48.137167   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:48.619368   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:48.631825   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:49.028760   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I1017 19:19:49.129091   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
W1017 19:19:49.133464   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:49.133464   13584 retry.go:31] will retry after 12.358655906s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:49.133703   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:49.630531   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:49.642985   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:50.127653   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:50.148892   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:50.623638   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:50.635404   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:51.123317   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:51.127738   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:51.621956   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:51.627409   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:52.120805   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:52.129363   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:52.396400   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W1017 19:19:52.514978   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:52.514978   13584 retry.go:31] will retry after 16.539116051s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:19:52.619703   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:52.623035   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:53.133725   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:53.148033   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:53.619674   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:53.636883   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:54.132786   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:54.146788   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:54.631880   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:54.651289   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:55.130110   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:55.144825   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:55.631484   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:55.643615   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:56.127695   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:56.139533   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:56.623291   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:56.627569   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:57.121936   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:57.128433   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:57.621174   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:57.632862   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:58.133316   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:58.144382   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:58.628307   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:58.632164   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:59.125482   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:59.128478   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:19:59.624216   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:19:59.626848   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:00.121274   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:00.126047   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:00.620869   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:00.625184   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:01.119139   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:01.130664   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:01.520711   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I1017 19:20:01.629476   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:01.632455   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
W1017 19:20:01.645503   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:01.645503   13584 retry.go:31] will retry after 7.211465349s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:02.128575   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:02.131580   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:02.627467   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:02.632162   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:03.121584   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:03.143469   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:03.635028   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:03.651818   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:04.133801   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:04.147892   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:04.635386   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:04.646258   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:05.132194   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:05.134577   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:05.628850   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:05.640586   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:06.124826   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:06.128504   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:06.633884   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:06.638317   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:07.131670   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:07.134724   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:07.628970   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:07.642362   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:08.130944   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:08.146837   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:08.631353   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:08.645519   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:08.903882   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:20:09.000915   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:09.001454   13584 retry.go:31] will retry after 12.855307452s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:09.103902   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I1017 19:20:09.125153   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:09.128507   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
W1017 19:20:09.205993   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:09.205993   13584 retry.go:31] will retry after 20.485214461s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:09.629578   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:09.635377   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:10.129291   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:10.150405   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:10.625219   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:10.637791   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:11.124192   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:11.142788   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:11.619247   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:11.630611   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:12.118803   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:12.122061   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:12.619564   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:12.631510   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:13.130053   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:13.144052   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:13.626758   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:13.641744   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:14.126291   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:14.139104   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:14.624989   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:14.635656   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:15.121839   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:15.126101   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:15.619566   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:15.632994   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:16.130925   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:16.142765   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:16.631575   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:16.636164   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:17.129732   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:17.133556   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:17.623115   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:17.626491   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:18.123156   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:18.132096   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:18.624126   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:18.627095   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:19.120457   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:19.125637   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:19.620873   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:19.632646   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:20.119251   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:20.130441   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:20.633962   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:20.646170   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:21.129976   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:21.141578   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:21.625151   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:21.627977   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:21.920252   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:20:22.051043   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:22.051043   13584 retry.go:31] will retry after 20.689183331s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:22.120285   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:22.129210   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:22.650790   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:22.750714   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:22.756518   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:22.793449   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:22.798308   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:22.835833   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:22.841252   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:22.879951   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:22.886575   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:22.923322   13584 logs.go:276] 0 containers: []
W1017 19:20:22.923322   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:22.928863   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:22.963094   13584 logs.go:276] 1 containers: [630b42f6c24d]
I1017 19:20:22.969090   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:23.000450   13584 logs.go:276] 0 containers: []
W1017 19:20:23.000450   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:23.006662   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:23.041542   13584 logs.go:276] 0 containers: []
W1017 19:20:23.041542   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:23.041542   13584 logs.go:123] Gathering logs for kube-controller-manager [630b42f6c24d] ...
I1017 19:20:23.041542   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 630b42f6c24d"
I1017 19:20:23.080502   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:23.080502   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:23.107205   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:23.107205   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:23.215539   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:23.203129    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.205523    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.207413    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.209914    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.212425    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:23.203129    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.205523    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.207413    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.209914    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:23.212425    2577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:23.215539   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:23.215539   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:23.251280   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:23.251280   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:23.296547   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:23.296547   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:23.344182   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:23.344182   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:23.421973   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:23.421973   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:23.569280   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:23.569280   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:23.652613   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:23.652613   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:23.772322   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:23.772322   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:23.848504   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:23.848504   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:26.404506   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:26.411779   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:26.428923   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:26.472703   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:26.478306   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:26.511783   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:26.517370   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:26.549523   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:26.555489   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:26.590565   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:26.596589   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:26.629754   13584 logs.go:276] 0 containers: []
W1017 19:20:26.629754   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:26.635375   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:26.668814   13584 logs.go:276] 1 containers: [630b42f6c24d]
I1017 19:20:26.674845   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:26.708211   13584 logs.go:276] 0 containers: []
W1017 19:20:26.708211   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:26.714245   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:26.746780   13584 logs.go:276] 0 containers: []
W1017 19:20:26.746780   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:26.746780   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:26.746780   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:26.814100   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:26.814100   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:26.882501   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:26.882501   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:27.028920   13584 logs.go:123] Gathering logs for kube-controller-manager [630b42f6c24d] ...
I1017 19:20:27.028920   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 630b42f6c24d"
I1017 19:20:27.074228   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:27.074228   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:27.123862   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:27.123862   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:27.148837   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:27.149386   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:27.191894   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:27.191894   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:27.240377   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:27.240435   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:27.309674   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:27.309674   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:27.407492   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:27.407492   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:27.527887   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:27.515783    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.518332    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.520962    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.523487    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.526136    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:27.515783    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.518332    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.520962    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.523487    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:27.526136    2794 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:27.528444   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:27.528444   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:29.727629   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W1017 19:20:29.831541   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:29.831541   13584 retry.go:31] will retry after 22.135633642s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I1017 19:20:30.102735   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:30.106480   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:30.116744   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:30.162317   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:30.170010   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:30.208166   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:30.216830   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:30.248064   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:30.253561   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:30.285644   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:30.292418   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:30.327204   13584 logs.go:276] 0 containers: []
W1017 19:20:30.327204   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:30.332257   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:30.369520   13584 logs.go:276] 1 containers: [630b42f6c24d]
I1017 19:20:30.375610   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:30.407381   13584 logs.go:276] 0 containers: []
W1017 19:20:30.407381   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:30.413661   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:30.444361   13584 logs.go:276] 0 containers: []
W1017 19:20:30.444361   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:30.444361   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:30.445881   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:30.531887   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:30.531887   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:30.568847   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:30.568847   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:30.612041   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:30.612041   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:30.653188   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:30.653188   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:30.718307   13584 logs.go:123] Gathering logs for kube-controller-manager [630b42f6c24d] ...
I1017 19:20:30.718307   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 630b42f6c24d"
I1017 19:20:30.763293   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:30.763293   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:30.787804   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:30.787804   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:30.887862   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:30.871028    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.873397    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.875865    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.878433    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.881299    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:30.871028    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.873397    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.875865    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.878433    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:30.881299    2941 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:30.887862   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:30.887862   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:30.937001   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:30.937001   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:31.013217   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:31.013217   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:31.091747   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:31.091747   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:33.719380   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:33.723302   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:33.731832   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:33.775099   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:33.782321   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:33.834823   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:33.839257   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:33.883439   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:33.892926   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:33.942322   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:33.949796   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:34.004755   13584 logs.go:276] 0 containers: []
W1017 19:20:34.004755   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:34.011432   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:34.048929   13584 logs.go:276] 2 containers: [668de80183be 630b42f6c24d]
I1017 19:20:34.055105   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:34.089072   13584 logs.go:276] 0 containers: []
W1017 19:20:34.089072   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:34.094601   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:34.133365   13584 logs.go:276] 0 containers: []
W1017 19:20:34.133365   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:34.133365   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:34.133365   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:34.242681   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:34.242681   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:34.266640   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:34.266640   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:34.301690   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:34.301690   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:34.360043   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:34.360043   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:34.496846   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:34.496846   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:34.597202   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:34.597202   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:34.686485   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:34.686485   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:34.804151   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:34.779417    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.781609    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.783894    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.786761    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.789126    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:34.779417    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.781609    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.783894    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.786761    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:34.789126    3159 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:34.804151   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:34.804151   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:34.872235   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:34.872235   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:35.023246   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:20:35.023246   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:20:35.065541   13584 logs.go:123] Gathering logs for kube-controller-manager [630b42f6c24d] ...
I1017 19:20:35.065541   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 630b42f6c24d"
I1017 19:20:35.099613   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:35.099613   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:37.665412   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:37.678569   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:37.702371   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:37.739424   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:37.745318   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:37.779735   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:37.785040   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:37.817686   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:37.823505   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:37.859204   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:37.864807   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:37.895001   13584 logs.go:276] 0 containers: []
W1017 19:20:37.895001   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:37.901270   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:37.934965   13584 logs.go:276] 2 containers: [668de80183be 630b42f6c24d]
I1017 19:20:37.940420   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:37.973624   13584 logs.go:276] 0 containers: []
W1017 19:20:37.973624   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:37.980787   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:38.015155   13584 logs.go:276] 0 containers: []
W1017 19:20:38.015155   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:38.015155   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:38.015155   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:38.136412   13584 logs.go:123] Gathering logs for kube-controller-manager [630b42f6c24d] ...
I1017 19:20:38.136412   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 630b42f6c24d"
I1017 19:20:38.175952   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:38.176041   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:38.264226   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:38.264226   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:38.289397   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:38.289397   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:38.396344   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:38.379133    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.381539    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.384088    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.386781    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.389585    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:38.379133    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.381539    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.384088    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.386781    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:38.389585    3291 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:38.396344   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:38.396344   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:38.447845   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:38.447845   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:38.523269   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:38.523269   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:38.594908   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:38.594908   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:38.636418   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:38.636418   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:38.703357   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:38.703357   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:38.797357   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:20:38.797357   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:20:38.832658   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:38.832658   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:41.382202   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:41.385313   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:41.395148   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:41.431729   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:41.437316   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:41.469008   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:41.474677   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:41.505918   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:41.511499   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:41.544763   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:41.551836   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:41.584157   13584 logs.go:276] 0 containers: []
W1017 19:20:41.584157   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:41.589802   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:41.630168   13584 logs.go:276] 2 containers: [668de80183be 630b42f6c24d]
I1017 19:20:41.637050   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:41.668101   13584 logs.go:276] 0 containers: []
W1017 19:20:41.668101   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:41.673623   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:41.710848   13584 logs.go:276] 0 containers: []
W1017 19:20:41.710848   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:41.710848   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:41.710848   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:41.799338   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:41.799338   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:41.900105   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:41.882983    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.885941    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.888492    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.891104    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.893469    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:41.882983    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.885941    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.888492    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.891104    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:41.893469    3441 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:41.900105   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:41.900618   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:41.994312   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:41.994312   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:42.082289   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:20:42.082289   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:20:42.124518   13584 logs.go:123] Gathering logs for kube-controller-manager [630b42f6c24d] ...
I1017 19:20:42.124518   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 630b42f6c24d"
I1017 19:20:42.162817   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:42.162817   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:42.215944   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:42.215944   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:42.283901   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:42.283901   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:42.310375   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:42.310375   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:42.351372   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:42.351372   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:42.403493   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:42.403493   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:42.447268   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:42.447268   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:42.761369   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W1017 19:20:42.850341   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W1017 19:20:42.850907   13584 out.go:270] â—  Enabling 'storage-provisioner' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I1017 19:20:45.076726   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:45.085411   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:45.108887   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:45.164754   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:45.173924   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:45.217620   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:45.224233   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:45.262553   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:45.270718   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:45.312056   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:45.322312   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:45.355377   13584 logs.go:276] 0 containers: []
W1017 19:20:45.355377   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:45.360780   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:45.393069   13584 logs.go:276] 2 containers: [668de80183be 630b42f6c24d]
I1017 19:20:45.398547   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:45.428603   13584 logs.go:276] 0 containers: []
W1017 19:20:45.428603   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:45.434087   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:45.460970   13584 logs.go:276] 0 containers: []
W1017 19:20:45.460970   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:45.460970   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:45.460970   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:45.553122   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:45.553122   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:45.652527   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:45.636430    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.639311    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.641795    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.644400    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.646510    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:45.636430    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.639311    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.641795    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.644400    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:45.646510    3634 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:45.652527   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:45.652527   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:45.702884   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:45.702884   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:45.789704   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:20:45.789704   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:20:45.832611   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:45.832861   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:45.900274   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:45.900274   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:45.923595   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:45.923595   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:45.960347   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:45.960347   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:46.009738   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:46.009738   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:46.085215   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:46.085215   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:46.202247   13584 logs.go:123] Gathering logs for kube-controller-manager [630b42f6c24d] ...
I1017 19:20:46.202247   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 630b42f6c24d"
W1017 19:20:46.239640   13584 logs.go:130] failed kube-controller-manager [630b42f6c24d]: command: /bin/bash -c "docker logs --tail 400 630b42f6c24d" /bin/bash -c "docker logs --tail 400 630b42f6c24d": Process exited with status 1
stdout:

stderr:
Error response from daemon: No such container: 630b42f6c24d
 output: 
** stderr ** 
Error response from daemon: No such container: 630b42f6c24d

** /stderr **
I1017 19:20:46.239640   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:46.239640   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:48.793761   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:48.803471   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:48.825220   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:48.867360   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:48.873993   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:48.907981   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:48.913460   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:48.946770   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:48.954254   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:48.986629   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:48.993436   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:49.029096   13584 logs.go:276] 0 containers: []
W1017 19:20:49.029096   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:49.036810   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:49.073310   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:20:49.078152   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:49.126653   13584 logs.go:276] 0 containers: []
W1017 19:20:49.126653   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:49.133241   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:49.180510   13584 logs.go:276] 0 containers: []
W1017 19:20:49.180510   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:49.180510   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:49.180510   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:49.205118   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:49.205118   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:49.258464   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:49.258464   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:49.322270   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:49.322270   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:49.506525   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:20:49.506525   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:20:49.549360   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:49.549360   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:49.604325   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:49.604325   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:49.719131   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:49.719131   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:49.759730   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:49.759730   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:49.825485   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:49.825485   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:49.935793   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:49.935793   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:50.024152   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:50.024152   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:50.149320   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:50.131363    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.133706    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.137245    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.142510    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.145074    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:50.131363    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.133706    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.137245    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.142510    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:50.145074    3877 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:52.002164   13584 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W1017 19:20:52.106172   13584 addons.go:457] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W1017 19:20:52.106172   13584 out.go:270] â—  Enabling 'default-storageclass' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.31.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I1017 19:20:52.115353   13584 out.go:177] ðŸŒŸ  Enabled addons: 
I1017 19:20:52.119537   13584 addons.go:510] duration metric: took 1m29.62701s for enable addons: enabled=[]
I1017 19:20:52.655675   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:52.672233   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:52.701038   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:52.738066   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:52.744173   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:52.772887   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:52.778392   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:52.813829   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:52.818737   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:52.847890   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:52.852788   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:52.882852   13584 logs.go:276] 0 containers: []
W1017 19:20:52.882852   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:52.889176   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:52.924112   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:20:52.929598   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:52.959651   13584 logs.go:276] 0 containers: []
W1017 19:20:52.959651   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:52.965965   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:52.998769   13584 logs.go:276] 0 containers: []
W1017 19:20:52.998769   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:52.998769   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:52.998769   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:53.106037   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:53.092964    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.095147    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.097333    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.099799    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.102162    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:53.092964    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.095147    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.097333    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.099799    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:53.102162    3962 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:53.106037   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:53.106037   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:53.149328   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:20:53.149328   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:20:53.183844   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:53.183844   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:53.227615   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:53.227615   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:20:53.291932   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:53.291932   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:53.390672   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:53.390672   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:53.430554   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:53.430554   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:53.488848   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:53.488848   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:53.575689   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:53.575689   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:53.655225   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:53.655225   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:53.816029   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:53.816029   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:56.347240   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:20:56.350009   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:20:56.355509   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:20:56.392968   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:20:56.399005   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:20:56.431703   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:20:56.439034   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:20:56.489214   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:20:56.498460   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:20:56.545797   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:20:56.551915   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:20:56.588792   13584 logs.go:276] 0 containers: []
W1017 19:20:56.588792   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:20:56.596891   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:20:56.634298   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:20:56.645877   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:20:56.691802   13584 logs.go:276] 0 containers: []
W1017 19:20:56.691802   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:20:56.702144   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:20:56.765630   13584 logs.go:276] 0 containers: []
W1017 19:20:56.765630   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:20:56.765630   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:20:56.766154   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:20:56.952344   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:20:56.935008    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.937951    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.940734    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.944554    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.947197    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:20:56.935008    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.937951    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.940734    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.944554    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:20:56.947197    4125 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:20:56.952344   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:20:56.952344   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:20:57.055764   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:20:57.055764   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:20:57.233202   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:20:57.233202   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:20:57.484426   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:20:57.484426   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:20:57.547340   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:20:57.547340   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:20:57.616011   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:20:57.616011   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:20:57.745071   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:20:57.745071   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:20:57.783329   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:20:57.783329   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:20:57.884506   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:20:57.884506   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:20:57.995836   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:20:57.995836   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:20:58.154978   13584 logs.go:123] Gathering logs for container status ...
I1017 19:20:58.154978   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:00.801063   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:00.805771   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:00.813474   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:00.867132   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:21:00.876005   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:00.921798   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:00.928044   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:00.976566   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:00.983018   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:01.024079   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:01.030027   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:01.071850   13584 logs.go:276] 0 containers: []
W1017 19:21:01.071850   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:01.078409   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:01.123492   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:21:01.130776   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:01.168448   13584 logs.go:276] 0 containers: []
W1017 19:21:01.168448   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:01.175121   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:01.239347   13584 logs.go:276] 0 containers: []
W1017 19:21:01.239347   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:01.239347   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:01.239347   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:01.307473   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:01.307473   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:01.384688   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:01.384688   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:01.511634   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:01.511634   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:01.706569   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:01.707093   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:01.745114   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:01.745114   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:01.831601   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:01.832141   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:01.979784   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:01.979784   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:02.105034   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:02.105183   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:02.246708   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:02.226601    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.229295    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.231960    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.234514    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.237207    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:02.226601    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.229295    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.231960    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.234514    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:02.237207    4345 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:02.246708   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:21:02.246708   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:21:02.331031   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:02.331031   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:02.415839   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:02.415839   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:05.124469   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:05.140224   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:05.155899   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:05.204813   13584 logs.go:276] 1 containers: [b5485cf82ba8]
I1017 19:21:05.211905   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:05.249062   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:05.255624   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:05.298916   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:05.309759   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:05.348330   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:05.356257   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:05.392941   13584 logs.go:276] 0 containers: []
W1017 19:21:05.392941   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:05.398460   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:05.440525   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:21:05.446448   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:05.480421   13584 logs.go:276] 0 containers: []
W1017 19:21:05.480421   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:05.487022   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:05.522538   13584 logs.go:276] 0 containers: []
W1017 19:21:05.522538   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:05.522538   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:05.522538   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:05.571018   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:05.571018   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:05.681308   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:05.681308   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:05.763650   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:05.763650   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:05.895693   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:05.895693   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:10.000270   13584 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 668de80183be": (4.1045768s)
I1017 19:21:10.006270   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:10.006270   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:10.353711   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:10.353711   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:10.666758   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:10.666758   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:10.806481   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:10.806481   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:10.846182   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:10.846182   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:11.160320   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:11.145159    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.147815    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.150121    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.152777    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.155442    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:11.145159    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.147815    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.150121    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.152777    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:11.155442    4517 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:11.160320   13584 logs.go:123] Gathering logs for kube-apiserver [b5485cf82ba8] ...
I1017 19:21:11.160320   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b5485cf82ba8"
I1017 19:21:11.234400   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:11.234400   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:13.957381   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:14.073612   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:14.080599   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:14.164268   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:14.171857   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:14.230458   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:14.249484   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:14.324741   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:14.333487   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:14.376051   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:14.381510   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:14.420617   13584 logs.go:276] 0 containers: []
W1017 19:21:14.420617   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:14.427157   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:14.467345   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:21:14.478048   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:14.519561   13584 logs.go:276] 0 containers: []
W1017 19:21:14.519865   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:14.529367   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:14.570110   13584 logs.go:276] 0 containers: []
W1017 19:21:14.570110   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:14.570110   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:14.570110   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:14.814403   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:14.814403   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:14.897571   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:14.897571   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:14.992829   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:14.992829   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:15.109957   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:15.109957   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:15.205539   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:15.205539   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:15.346243   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:15.346243   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:15.537436   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:15.537436   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:15.611123   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:15.611123   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:15.663365   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:15.663365   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:15.710169   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:15.710169   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:15.928781   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:15.913816    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.916294    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.918860    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.921429    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.924350    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:15.913816    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.916294    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.918860    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.921429    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:15.924350    4757 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:15.928781   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:15.928781   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:18.511396   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:18.533046   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:18.539193   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:18.596660   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:18.614772   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:18.662875   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:18.680933   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:18.725661   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:18.747892   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:18.863615   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:18.874055   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:18.927274   13584 logs.go:276] 0 containers: []
W1017 19:21:18.927274   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:18.939239   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:18.987268   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:21:18.994025   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:19.038864   13584 logs.go:276] 0 containers: []
W1017 19:21:19.038864   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:19.053571   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:19.112279   13584 logs.go:276] 0 containers: []
W1017 19:21:19.112279   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:19.112279   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:19.112279   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:19.178115   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:19.179130   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:19.260323   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:19.260323   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:19.363846   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:19.363846   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:19.677974   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:19.677974   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:19.858226   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:19.862233   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:20.008112   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:20.008112   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:22.688496   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:22.688496   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:22.755563   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:22.755563   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:23.047873   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:23.007164    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.019941    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.022025    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.024296    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.026247    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:23.007164    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.019941    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.022025    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.024296    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:23.026247    4912 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:23.047873   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:23.047873   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:23.139303   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:23.139303   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:23.887757   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:23.887757   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:26.464102   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:26.467679   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:26.475960   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:26.517037   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:26.523963   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:26.558977   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:26.564529   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:26.601307   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:26.608561   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:26.645370   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:26.651468   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:26.683050   13584 logs.go:276] 0 containers: []
W1017 19:21:26.683050   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:26.689992   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:26.729373   13584 logs.go:276] 1 containers: [668de80183be]
I1017 19:21:26.735446   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:26.772045   13584 logs.go:276] 0 containers: []
W1017 19:21:26.772045   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:26.777527   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:26.813353   13584 logs.go:276] 0 containers: []
W1017 19:21:26.813353   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:26.813353   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:26.813353   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:26.845018   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:26.845018   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:26.898235   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:26.898235   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:26.950287   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:26.950287   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:27.033430   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:27.033430   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:27.073173   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:27.073173   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:27.149484   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:27.149484   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:27.278399   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:27.278399   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:27.387686   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:27.374985    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.377479    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.379819    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.382375    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.385166    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:27.374985    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.377479    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.379819    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.382375    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:27.385166    5069 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:27.387686   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:27.387686   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:27.426089   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:27.426089   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:27.574761   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:27.574761   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:27.737922   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:27.737922   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:30.356975   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:30.448357   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:30.465529   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:30.574015   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:30.596746   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:30.675423   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:30.685338   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:30.775548   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:30.791259   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:30.924180   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:30.949924   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:31.028832   13584 logs.go:276] 0 containers: []
W1017 19:21:31.028832   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:31.039673   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:31.115595   13584 logs.go:276] 2 containers: [950676de58d2 668de80183be]
I1017 19:21:31.129274   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:31.181389   13584 logs.go:276] 0 containers: []
W1017 19:21:31.181389   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:31.193085   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:31.255550   13584 logs.go:276] 0 containers: []
W1017 19:21:31.255550   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:31.255550   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:21:31.255550   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:21:31.521447   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:31.521447   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:31.744383   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:31.744383   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:31.889456   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:31.889456   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:32.133902   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:32.133902   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:32.299013   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:32.278364    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.281265    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.283932    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.287352    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.290423    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:32.278364    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.281265    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.283932    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.287352    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:32.290423    5258 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:32.299013   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:32.299013   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:32.551582   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:32.551582   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:32.735426   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:32.735767   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:33.237554   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:33.237554   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:33.326923   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:33.326923   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:33.377140   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:33.377140   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:33.527690   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:33.527690   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:34.005295   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:34.005295   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:36.631772   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:36.648545   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:36.780798   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:36.856682   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:36.863149   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:36.932009   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:36.982254   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:37.088823   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:37.115690   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:37.159659   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:37.165763   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:37.213723   13584 logs.go:276] 0 containers: []
W1017 19:21:37.213723   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:37.219534   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:37.265772   13584 logs.go:276] 2 containers: [950676de58d2 668de80183be]
I1017 19:21:37.275802   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:37.313513   13584 logs.go:276] 0 containers: []
W1017 19:21:37.313513   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:37.322824   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:37.363511   13584 logs.go:276] 0 containers: []
W1017 19:21:37.363511   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:37.363511   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:37.363511   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:37.416774   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:37.416774   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:37.478787   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:37.478787   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:37.615599   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:37.615599   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:37.712453   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:37.712453   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:37.830848   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:37.830848   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:37.929428   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:37.929428   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:38.030776   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:38.030776   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:38.135002   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:38.135002   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:38.259978   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:38.259978   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:38.287047   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:38.287047   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:38.400865   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:38.384299    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.386746    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.389267    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.391652    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.394190    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:38.384299    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.386746    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.389267    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.391652    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:38.394190    5476 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:38.400865   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:38.401005   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:38.615092   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:21:38.615092   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:21:41.178803   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:41.184610   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:41.193617   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:41.242549   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:41.251136   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:41.293820   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:41.304951   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:41.350601   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:41.359353   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:41.395558   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:41.406357   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:41.444439   13584 logs.go:276] 0 containers: []
W1017 19:21:41.444439   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:41.454778   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:41.513930   13584 logs.go:276] 2 containers: [950676de58d2 668de80183be]
I1017 19:21:41.540628   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:41.598770   13584 logs.go:276] 0 containers: []
W1017 19:21:41.599230   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:41.622158   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:41.710492   13584 logs.go:276] 0 containers: []
W1017 19:21:41.710492   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:41.710492   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:21:41.710492   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:21:41.812268   13584 logs.go:123] Gathering logs for kube-controller-manager [668de80183be] ...
I1017 19:21:41.812268   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 668de80183be"
I1017 19:21:41.881277   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:41.881824   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:42.073485   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:42.073485   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:42.296969   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:42.279676    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.282381    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.284666    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.287198    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.289278    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:42.279676    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.282381    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.284666    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.287198    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:42.289278    5614 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:42.296969   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:42.296969   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:42.345800   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:42.345800   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:42.423712   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:42.423712   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:42.562469   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:42.562469   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:42.741041   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:42.741041   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:42.775414   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:42.775414   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:42.835539   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:42.835539   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:42.959910   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:42.959910   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:43.030869   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:43.030869   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:45.637946   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:45.647006   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:45.663415   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:46.329285   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:46.395504   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:46.911878   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:46.925503   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:47.759024   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:47.775696   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:47.839786   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:47.855703   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:47.977536   13584 logs.go:276] 0 containers: []
W1017 19:21:47.977536   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:48.010300   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:48.263371   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:21:48.281874   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:48.409463   13584 logs.go:276] 0 containers: []
W1017 19:21:48.409463   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:48.440935   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:48.579096   13584 logs.go:276] 0 containers: []
W1017 19:21:48.579096   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:48.579096   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:48.579096   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:49.195160   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:49.196164   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:21:49.943312   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:49.943312   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:50.225349   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:50.225349   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:50.380288   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:50.380288   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:50.643861   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:50.643861   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:50.929801   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:50.895576    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.898218    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.918058    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.920711    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.923221    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:50.895576    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.898218    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.918058    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.920711    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:50.923221    5811 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:50.929801   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:50.929801   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:51.055174   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:51.055174   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:51.344631   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:51.344631   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:52.423265   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:21:52.423265   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:21:52.795467   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:52.795467   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:53.223337   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:53.223337   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:55.776957   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:21:55.786715   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:21:55.812862   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:21:56.071937   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:21:56.113877   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:21:56.557306   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:21:56.565241   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:21:56.876971   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:21:56.888483   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:21:57.747223   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:21:57.772403   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:21:57.856823   13584 logs.go:276] 0 containers: []
W1017 19:21:57.856823   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:21:57.912706   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:21:57.987430   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:21:57.994622   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:21:58.056083   13584 logs.go:276] 0 containers: []
W1017 19:21:58.056083   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:21:58.073859   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:21:58.570643   13584 logs.go:276] 0 containers: []
W1017 19:21:58.572654   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:21:58.573654   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:21:58.573654   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:21:58.925193   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:21:58.925193   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:21:59.013202   13584 logs.go:123] Gathering logs for container status ...
I1017 19:21:59.013202   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:21:59.124799   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:21:59.124799   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:21:59.154848   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:21:59.154848   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:21:59.286253   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:21:59.265196    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.268606    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.271987    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.274547    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.277199    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:21:59.265196    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.268606    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.271987    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.274547    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:21:59.277199    5957 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:21:59.286253   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:21:59.286253   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:21:59.334834   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:21:59.334834   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:21:59.388047   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:21:59.388047   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:21:59.495360   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:21:59.495360   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:21:59.602135   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:21:59.602135   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:21:59.828567   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:21:59.828567   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:21:59.878946   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:21:59.878946   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:02.447987   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:02.453281   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:02.460956   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:02.510809   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:02.517377   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:02.555044   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:02.560569   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:02.597444   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:02.604764   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:02.638968   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:02.649488   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:02.690942   13584 logs.go:276] 0 containers: []
W1017 19:22:02.690942   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:02.698203   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:02.742596   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:02.763076   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:02.814802   13584 logs.go:276] 0 containers: []
W1017 19:22:02.814802   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:02.822765   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:02.865316   13584 logs.go:276] 0 containers: []
W1017 19:22:02.865316   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:02.865316   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:02.865316   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:02.924708   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:02.924708   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:02.976929   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:02.976929   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:03.081741   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:03.081741   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:03.270912   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:03.270912   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:03.328439   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:03.328439   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:03.506582   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:03.506582   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:03.533962   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:03.534024   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:03.686285   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:03.670123    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.672726    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.674955    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.677299    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.679875    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:03.670123    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.672726    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.674955    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.677299    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:03.679875    6141 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:03.686285   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:03.686285   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:03.740802   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:03.740802   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:03.876701   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:03.876701   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:03.954687   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:03.954687   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:06.569099   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:06.573632   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:06.581482   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:06.620122   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:06.625585   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:06.671131   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:06.679815   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:06.725348   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:06.732728   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:06.771439   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:06.781658   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:06.826176   13584 logs.go:276] 0 containers: []
W1017 19:22:06.826176   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:06.837131   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:06.878472   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:06.886829   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:06.921593   13584 logs.go:276] 0 containers: []
W1017 19:22:06.921593   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:06.930206   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:06.968235   13584 logs.go:276] 0 containers: []
W1017 19:22:06.968235   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:06.968235   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:06.968235   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:07.121640   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:07.121640   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:07.151741   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:07.151741   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:07.196583   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:07.196583   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:07.308546   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:07.308546   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:07.349970   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:07.349970   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:07.501835   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:07.480040    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.483453    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.486115    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.488693    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.491219    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:07.480040    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.483453    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.486115    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.488693    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:07.491219    6284 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:07.502354   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:07.502354   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:07.554907   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:07.554907   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:07.605786   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:07.605786   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:07.708027   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:07.708027   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:07.883196   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:07.883196   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:07.943529   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:07.943529   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:10.531074   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:10.539592   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:10.554194   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:10.603838   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:10.613532   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:10.696154   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:10.712629   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:10.780718   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:10.793316   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:10.863206   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:10.871036   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:10.923520   13584 logs.go:276] 0 containers: []
W1017 19:22:10.923520   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:10.931628   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:10.994053   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:11.000705   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:11.043614   13584 logs.go:276] 0 containers: []
W1017 19:22:11.043614   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:11.051853   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:11.095693   13584 logs.go:276] 0 containers: []
W1017 19:22:11.095693   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:11.095693   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:11.095693   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:11.276868   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:11.276868   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:11.314350   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:11.314350   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:11.455188   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:11.434038    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.438397    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.443150    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.446018    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.448684    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:11.434038    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.438397    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.443150    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.446018    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:11.448684    6417 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:11.455188   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:11.455188   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:11.507627   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:11.507627   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:11.569584   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:11.569584   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:12.105604   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:12.105604   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:12.399489   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:12.399489   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:12.596118   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:12.596118   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:12.670377   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:12.670883   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:12.804172   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:12.804172   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:12.882631   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:12.882631   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:15.549353   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:15.595267   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:15.606009   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:15.686812   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:15.699658   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:15.756398   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:15.768453   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:15.822966   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:15.830779   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:15.901678   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:15.912508   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:15.956048   13584 logs.go:276] 0 containers: []
W1017 19:22:15.956048   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:15.965901   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:16.026501   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:16.033729   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:16.110391   13584 logs.go:276] 0 containers: []
W1017 19:22:16.110391   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:16.123106   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:16.286727   13584 logs.go:276] 0 containers: []
W1017 19:22:16.286727   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:16.286727   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:16.286727   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:16.442477   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:16.442477   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:16.685790   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:16.656800    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.659765    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.662311    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.665424    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.668945    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:16.656800    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.659765    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.662311    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.665424    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:16.668945    6577 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:16.685790   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:16.685790   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:17.056919   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:17.056919   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:17.275813   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:17.275813   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:17.368665   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:17.368665   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:17.605276   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:17.605276   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:17.931301   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:17.931301   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:18.007092   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:18.007092   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:18.091080   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:18.091080   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:18.275829   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:18.275829   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:18.620590   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:18.620590   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:21.358787   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:21.365723   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:21.383595   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:21.435246   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:21.445368   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:21.505785   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:21.516064   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:21.561599   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:21.573094   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:21.612305   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:21.622976   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:21.688184   13584 logs.go:276] 0 containers: []
W1017 19:22:21.689724   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:21.706200   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:21.766944   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:21.780469   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:21.827904   13584 logs.go:276] 0 containers: []
W1017 19:22:21.827904   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:21.834994   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:21.893106   13584 logs.go:276] 0 containers: []
W1017 19:22:21.893106   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:21.893106   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:21.893106   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:22.011357   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:22.011357   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:22.195477   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:22.176376    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.179144    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.181832    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.184621    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.187833    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:22.176376    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.179144    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.181832    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.184621    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:22.187833    6738 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:22.195477   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:22.195477   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:22.282882   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:22.282882   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:22.421531   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:22.421531   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:22.611417   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:22.611417   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:22.771986   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:22.771986   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:22.819457   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:22.819457   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:22.904906   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:22.904906   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:23.064827   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:23.064827   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:23.093337   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:23.093337   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:23.149448   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:23.149448   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:25.750021   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:25.757873   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:25.773317   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:25.820280   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:25.825383   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:25.870047   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:25.880034   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:25.928573   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:25.935927   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:25.984961   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:25.994114   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:26.043409   13584 logs.go:276] 0 containers: []
W1017 19:22:26.043409   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:26.055296   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:26.115654   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:26.128896   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:26.182265   13584 logs.go:276] 0 containers: []
W1017 19:22:26.182265   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:26.190311   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:26.227666   13584 logs.go:276] 0 containers: []
W1017 19:22:26.227666   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:26.227666   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:26.227666   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:26.356110   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:26.341739    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.344024    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.346843    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.349632    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.353250    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:26.341739    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.344024    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.346843    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.349632    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:26.353250    6909 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:26.356110   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:26.356110   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:26.406144   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:26.406144   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:26.520210   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:26.520210   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:26.721866   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:26.722421   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:26.790646   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:26.790646   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:26.868316   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:26.868316   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:27.357766   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:27.357766   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:27.608361   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:27.608361   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:27.673572   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:27.673572   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:27.749923   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:27.749923   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:27.869870   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:27.869870   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:30.455602   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:30.473495   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:30.481961   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:30.522336   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:30.528382   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:30.572382   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:30.583000   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:30.677913   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:30.708556   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:30.771265   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:30.788127   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:30.944545   13584 logs.go:276] 0 containers: []
W1017 19:22:30.944545   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:30.972516   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:31.034952   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:31.044812   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:31.114321   13584 logs.go:276] 0 containers: []
W1017 19:22:31.114321   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:31.121859   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:31.178328   13584 logs.go:276] 0 containers: []
W1017 19:22:31.178328   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:31.178328   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:31.178328   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:31.272975   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:31.272975   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:31.372525   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:31.372525   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:31.521534   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:31.521534   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:31.567148   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:31.567148   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:31.613793   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:31.613793   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:31.668716   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:31.668716   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:31.795088   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:31.764662    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.767363    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.769935    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.772350    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.777701    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:31.764662    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.767363    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.769935    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.772350    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:31.777701    7120 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:31.795088   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:31.795088   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:31.947739   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:31.947739   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:32.051727   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:32.051727   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:32.192241   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:32.192241   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:32.415624   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:32.415624   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:34.967116   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:34.989035   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:35.001045   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:35.049573   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:35.059521   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:35.126740   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:35.138405   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:35.177754   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:35.185159   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:35.225852   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:35.235722   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:35.273999   13584 logs.go:276] 0 containers: []
W1017 19:22:35.273999   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:35.282020   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:35.323657   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:35.334932   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:35.401094   13584 logs.go:276] 0 containers: []
W1017 19:22:35.401094   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:35.409493   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:35.459231   13584 logs.go:276] 0 containers: []
W1017 19:22:35.459231   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:35.459231   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:35.459231   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:35.539478   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:35.539478   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:35.563771   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:35.563771   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:35.610411   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:35.610411   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:35.694584   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:35.694584   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:35.817602   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:35.817602   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:35.975747   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:35.975747   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:36.060797   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:36.060797   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:36.234379   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:36.234379   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:36.347047   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:36.329720    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.333841    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.336153    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.338763    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.340974    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:36.329720    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.333841    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.336153    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.338763    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:36.340974    7278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:36.347047   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:36.347047   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:36.396394   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:36.396394   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:36.451752   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:36.451752   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:39.022119   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:39.036814   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:39.055135   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:39.104097   13584 logs.go:276] 1 containers: [2196b67ad8fe]
I1017 19:22:39.110432   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:39.149287   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:39.157588   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:39.204074   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:39.211039   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:39.252447   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:39.264762   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:39.304277   13584 logs.go:276] 0 containers: []
W1017 19:22:39.304277   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:39.311419   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:39.359736   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:39.366847   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:39.402485   13584 logs.go:276] 0 containers: []
W1017 19:22:39.402485   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:39.413130   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:39.453440   13584 logs.go:276] 0 containers: []
W1017 19:22:39.453440   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:39.453440   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:39.453440   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:39.534943   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:39.534943   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:39.655214   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:39.639822    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.642882    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.645725    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.648358    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.650696    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:39.639822    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.642882    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.645725    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.648358    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:39.650696    7390 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:39.655214   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:39.655214   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:39.715747   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:39.715747   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:39.781176   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:39.781176   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:39.888116   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:39.888116   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:40.011509   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:40.011509   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:40.062330   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:40.062330   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:40.221853   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:40.221853   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:40.251138   13584 logs.go:123] Gathering logs for kube-apiserver [2196b67ad8fe] ...
I1017 19:22:40.251138   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2196b67ad8fe"
I1017 19:22:40.299185   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:40.299185   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:40.447289   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:40.447289   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:42.992969   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:42.996214   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:43.003185   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:43.049819   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:22:43.059304   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:43.103153   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:43.110459   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:43.152483   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:43.160533   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:43.198386   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:43.207510   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:43.252561   13584 logs.go:276] 0 containers: []
W1017 19:22:43.252561   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:43.260207   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:43.307897   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:43.316947   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:43.364059   13584 logs.go:276] 0 containers: []
W1017 19:22:43.364059   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:43.371307   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:43.413634   13584 logs.go:276] 0 containers: []
W1017 19:22:43.413634   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:43.413634   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:43.413634   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:43.479738   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:43.479738   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:43.606857   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:43.591511    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.593461    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.596119    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.598810    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.601233    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:43.591511    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.593461    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.596119    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.598810    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:43.601233    7616 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:43.606857   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:22:43.606857   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:22:43.653765   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:43.653765   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:43.705863   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:43.705863   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:43.852601   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:43.852601   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:44.013204   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:44.013204   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:44.055525   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:44.055525   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:44.130690   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:44.130690   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:44.255997   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:44.255997   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:44.415839   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:44.415839   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:44.443651   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:44.443651   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:47.035741   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:47.038586   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:47.044622   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:47.099701   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:22:47.107051   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:47.159523   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:47.166122   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:47.210548   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:47.234314   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:47.288126   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:47.295794   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:47.341177   13584 logs.go:276] 0 containers: []
W1017 19:22:47.341177   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:47.347815   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:47.385946   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:47.394726   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:47.433966   13584 logs.go:276] 0 containers: []
W1017 19:22:47.433966   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:47.442307   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:47.484810   13584 logs.go:276] 0 containers: []
W1017 19:22:47.484810   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:47.485324   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:47.485324   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:47.576818   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:47.576818   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:47.699986   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:47.699986   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:47.725466   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:47.725466   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:47.878537   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:47.861093    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.863957    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.866656    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.869091    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.872777    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:47.861093    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.863957    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.866656    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.869091    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:47.872777    7790 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:47.878537   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:22:47.878537   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:22:47.923539   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:47.923539   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:47.975876   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:47.975876   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:48.022738   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:48.022738   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:48.111111   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:48.111111   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:48.242851   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:48.242851   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:48.408625   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:48.408625   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:48.518855   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:48.518855   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:51.096702   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:51.102725   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:51.136495   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:51.244108   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:22:51.274931   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:51.331581   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:51.340583   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:51.415501   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:51.429892   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:51.480488   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:51.506914   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:51.553414   13584 logs.go:276] 0 containers: []
W1017 19:22:51.553414   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:51.561291   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:51.602824   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:51.610878   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:51.656769   13584 logs.go:276] 0 containers: []
W1017 19:22:51.656769   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:51.669628   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:51.714242   13584 logs.go:276] 0 containers: []
W1017 19:22:51.714242   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:51.714242   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:51.714242   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:51.870999   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:22:51.870999   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:22:51.917929   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:51.917929   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:51.983260   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:51.983342   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:52.050453   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:52.050453   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:52.122174   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:52.122174   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:52.203495   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:52.203495   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:52.236203   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:52.236724   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:52.391230   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:52.373957    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.376571    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.380735    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.383535    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.387793    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:52.373957    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.376571    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.380735    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.383535    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:52.387793    7975 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:52.391230   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:52.391230   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:52.488632   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:52.488632   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:52.675599   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:52.675599   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:53.273502   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:53.273502   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:55.881936   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:55.886341   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:55.900654   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:55.954327   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:22:55.960367   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:56.001873   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:56.007013   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:56.044287   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:56.053509   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:56.091702   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:56.097857   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:22:56.132942   13584 logs.go:276] 0 containers: []
W1017 19:22:56.132942   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:22:56.138569   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:22:56.176891   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:22:56.183582   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:22:56.231537   13584 logs.go:276] 0 containers: []
W1017 19:22:56.231537   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:22:56.237047   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:22:56.273078   13584 logs.go:276] 0 containers: []
W1017 19:22:56.273078   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:22:56.273078   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:22:56.273078   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:22:56.424031   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:22:56.424031   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:22:56.475691   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:22:56.475691   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:22:56.630382   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:22:56.630382   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:22:56.683278   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:22:56.683278   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:22:56.735116   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:22:56.735116   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:22:56.810691   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:22:56.810691   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:22:56.919808   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:22:56.919808   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:22:56.948053   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:22:56.948053   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:22:57.060123   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:22:57.048117    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.050610    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.053137    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.055562    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.058026    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:22:57.048117    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.050610    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.053137    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.055562    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:22:57.058026    8147 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:22:57.060123   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:22:57.060123   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:22:57.103541   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:22:57.103541   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:22:57.143324   13584 logs.go:123] Gathering logs for container status ...
I1017 19:22:57.143324   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:22:59.731513   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:22:59.735541   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:22:59.747359   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:22:59.812732   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:22:59.820457   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:22:59.863879   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:22:59.874823   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:22:59.914667   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:22:59.922295   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:22:59.970056   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:22:59.983027   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:23:00.039663   13584 logs.go:276] 0 containers: []
W1017 19:23:00.039663   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:23:00.049173   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:23:00.091538   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:23:00.101066   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:23:00.143370   13584 logs.go:276] 0 containers: []
W1017 19:23:00.143879   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:23:00.150067   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:23:00.187110   13584 logs.go:276] 0 containers: []
W1017 19:23:00.187110   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:23:00.187110   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:23:00.187110   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:23:00.246924   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:23:00.246924   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:23:00.376939   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:23:00.376939   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:23:00.419291   13584 logs.go:123] Gathering logs for container status ...
I1017 19:23:00.419291   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:23:00.513276   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:23:00.513276   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:23:00.669454   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:23:00.669454   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:23:00.696745   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:23:00.696745   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:23:00.809541   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:23:00.793311    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.795935    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.798616    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.801011    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.803361    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:23:00.793311    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.795935    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.798616    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.801011    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:00.803361    8297 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:23:00.809541   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:23:00.809541   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:23:00.924392   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:23:00.924392   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:23:00.973645   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:23:00.973645   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:23:01.016222   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:23:01.016222   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:23:01.064399   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:23:01.064399   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:23:03.663978   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:23:03.683951   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:23:03.697217   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:23:03.744322   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:23:03.755492   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:23:03.801718   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:23:03.807678   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:23:03.844403   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:23:03.851172   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:23:03.886770   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:23:03.893835   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:23:03.932372   13584 logs.go:276] 0 containers: []
W1017 19:23:03.932372   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:23:03.940557   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:23:04.020014   13584 logs.go:276] 1 containers: [950676de58d2]
I1017 19:23:04.029544   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:23:04.080565   13584 logs.go:276] 0 containers: []
W1017 19:23:04.080565   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:23:04.091905   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:23:04.126084   13584 logs.go:276] 0 containers: []
W1017 19:23:04.126084   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:23:04.126084   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:23:04.126084   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:23:04.180141   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:23:04.180141   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:23:04.281148   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:23:04.281148   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:23:04.325649   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:23:04.325649   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:23:04.477031   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:23:04.477031   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:23:04.522852   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:23:04.522852   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:23:04.576011   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:23:04.576011   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:23:04.690868   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:23:04.690868   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:23:04.829524   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:23:04.829524   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:23:04.879146   13584 logs.go:123] Gathering logs for container status ...
I1017 19:23:04.879146   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:23:04.951339   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:23:04.951339   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:23:04.994171   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:23:04.994171   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:23:05.114955   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:23:05.098392    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.102083    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.104428    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.106712    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.109176    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:23:05.098392    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.102083    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.104428    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.106712    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:05.109176    8490 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:23:07.618686   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:23:07.626049   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:23:07.643830   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:23:07.695856   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:23:07.705959   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:23:07.753177   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:23:07.761771   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:23:07.810711   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:23:07.820626   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:23:07.876163   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:23:07.883274   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:23:07.941674   13584 logs.go:276] 0 containers: []
W1017 19:23:07.941674   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:23:07.951433   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:23:08.022510   13584 logs.go:276] 2 containers: [872971b21a7a 950676de58d2]
I1017 19:23:08.029819   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:23:08.075813   13584 logs.go:276] 0 containers: []
W1017 19:23:08.075813   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:23:08.085880   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:23:08.132571   13584 logs.go:276] 0 containers: []
W1017 19:23:08.132571   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:23:08.132571   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:23:08.132571   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:23:08.186155   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:23:08.186155   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:23:08.314918   13584 logs.go:123] Gathering logs for container status ...
I1017 19:23:08.314918   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:23:08.449721   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:23:08.449721   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:23:08.491198   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:23:08.491198   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:23:08.652578   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:23:08.636460    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.639312    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.641830    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.645254    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.647829    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:23:08.636460    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.639312    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.641830    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.645254    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:08.647829    8653 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:23:08.652578   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:23:08.652578   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:23:08.704933   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:23:08.704933   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:23:08.754975   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:23:08.754975   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:23:08.888188   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:23:08.888188   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:23:09.049466   13584 logs.go:123] Gathering logs for kube-controller-manager [872971b21a7a] ...
I1017 19:23:09.049466   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 872971b21a7a"
I1017 19:23:09.094881   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:23:09.094881   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:23:09.151520   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:23:09.151520   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:23:09.351162   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:23:09.351162   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:23:11.949671   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:23:11.957642   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:23:11.978359   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:23:12.018768   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:23:12.024292   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:23:12.070870   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:23:12.080576   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:23:12.122443   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:23:12.132512   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:23:12.175882   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:23:12.182979   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:23:12.220812   13584 logs.go:276] 0 containers: []
W1017 19:23:12.220812   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:23:12.231332   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:23:12.268371   13584 logs.go:276] 2 containers: [872971b21a7a 950676de58d2]
I1017 19:23:12.274431   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:23:12.310634   13584 logs.go:276] 0 containers: []
W1017 19:23:12.310634   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:23:12.316224   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:23:12.353271   13584 logs.go:276] 0 containers: []
W1017 19:23:12.353271   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:23:12.353271   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:23:12.353271   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:23:12.462331   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:23:12.462331   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:23:12.683100   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:23:12.683100   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:23:12.745011   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:23:12.745011   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:23:12.825579   13584 logs.go:123] Gathering logs for container status ...
I1017 19:23:12.825579   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:23:12.913334   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:23:12.913334   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:23:12.944650   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:23:12.944650   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:23:12.985385   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:23:12.986053   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:23:13.041740   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:23:13.042281   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:23:13.096551   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:23:13.096551   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:23:13.172918   13584 logs.go:123] Gathering logs for kube-controller-manager [872971b21a7a] ...
I1017 19:23:13.172918   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 872971b21a7a"
I1017 19:23:13.218664   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:23:13.218664   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:23:13.364330   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:23:13.364330   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:23:13.515732   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:23:13.493536    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.496183    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.498675    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.501460    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.508608    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:23:13.493536    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.496183    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.498675    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.501460    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:13.508608    8882 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:23:16.016535   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:23:16.020647   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:23:16.028288   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:23:16.063518   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:23:16.070108   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:23:16.111457   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:23:16.116497   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:23:16.155100   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:23:16.161164   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:23:16.206548   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:23:16.212653   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:23:16.250607   13584 logs.go:276] 0 containers: []
W1017 19:23:16.250607   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:23:16.256149   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:23:16.293753   13584 logs.go:276] 2 containers: [872971b21a7a 950676de58d2]
I1017 19:23:16.299855   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:23:16.336096   13584 logs.go:276] 0 containers: []
W1017 19:23:16.336096   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:23:16.343654   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:23:16.379745   13584 logs.go:276] 0 containers: []
W1017 19:23:16.379745   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:23:16.379745   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:23:16.379745   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:23:16.547672   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:23:16.547672   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:23:16.576352   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:23:16.576352   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:23:16.619634   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:23:16.619634   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:23:16.676915   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:23:16.676915   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:23:16.794161   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:23:16.794161   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:23:16.938595   13584 logs.go:123] Gathering logs for kube-controller-manager [872971b21a7a] ...
I1017 19:23:16.938595   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 872971b21a7a"
I1017 19:23:17.002415   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:23:17.002415   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:23:17.070407   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:23:17.070407   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:23:17.185814   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:23:17.167066    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.171473    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.176374    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.179194    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.181545    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:23:17.167066    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.171473    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.176374    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.179194    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:17.181545    9013 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:23:17.185814   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:23:17.185814   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:23:17.236218   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:23:17.236218   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:23:17.315260   13584 logs.go:123] Gathering logs for kube-controller-manager [950676de58d2] ...
I1017 19:23:17.315260   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 950676de58d2"
I1017 19:23:17.359825   13584 logs.go:123] Gathering logs for container status ...
I1017 19:23:17.359825   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:23:19.945478   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:23:19.954944   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:23:19.968184   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:23:20.007559   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:23:20.013887   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:23:20.053875   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:23:20.063499   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:23:20.103321   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:23:20.109418   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:23:20.151130   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:23:20.156182   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:23:20.191917   13584 logs.go:276] 0 containers: []
W1017 19:23:20.191917   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:23:20.198211   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:23:20.240381   13584 logs.go:276] 1 containers: [872971b21a7a]
I1017 19:23:20.248634   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:23:20.286736   13584 logs.go:276] 0 containers: []
W1017 19:23:20.286736   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:23:20.293085   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:23:20.332702   13584 logs.go:276] 0 containers: []
W1017 19:23:20.332702   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:23:20.332702   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:23:20.332702   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:23:20.405202   13584 logs.go:123] Gathering logs for kube-controller-manager [872971b21a7a] ...
I1017 19:23:20.405202   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 872971b21a7a"
I1017 19:23:20.448856   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:23:20.448856   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:23:20.504874   13584 logs.go:123] Gathering logs for container status ...
I1017 19:23:20.504874   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:23:20.583505   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:23:20.583505   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:23:20.734887   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:23:20.734887   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:23:20.759996   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:23:20.759996   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:23:20.883667   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:23:20.867991    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.870704    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.873093    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.876380    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.879382    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:23:20.867991    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.870704    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.873093    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.876380    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:20.879382    9182 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:23:20.883667   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:23:20.883667   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:23:20.940866   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:23:20.940866   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:23:20.987266   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:23:20.987266   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:23:21.040165   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:23:21.040165   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:23:21.145097   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:23:21.145097   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:23:23.817758   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:23:23.829860   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:23:23.846238   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I1017 19:23:23.892328   13584 logs.go:276] 1 containers: [69ea2c5418d3]
I1017 19:23:23.899094   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I1017 19:23:23.937738   13584 logs.go:276] 2 containers: [42588bc5d0bd b41b269d7bdc]
I1017 19:23:23.943818   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I1017 19:23:23.992426   13584 logs.go:276] 1 containers: [2c99b8895a55]
I1017 19:23:23.997840   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I1017 19:23:24.042671   13584 logs.go:276] 2 containers: [dfb3e3be7dd3 81c22dae6e21]
I1017 19:23:24.049191   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I1017 19:23:24.085377   13584 logs.go:276] 0 containers: []
W1017 19:23:24.085377   13584 logs.go:278] No container was found matching "kube-proxy"
I1017 19:23:24.094547   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I1017 19:23:24.132840   13584 logs.go:276] 1 containers: [872971b21a7a]
I1017 19:23:24.138852   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I1017 19:23:24.173795   13584 logs.go:276] 0 containers: []
W1017 19:23:24.173795   13584 logs.go:278] No container was found matching "kindnet"
I1017 19:23:24.180336   13584 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I1017 19:23:24.217851   13584 logs.go:276] 0 containers: []
W1017 19:23:24.217851   13584 logs.go:278] No container was found matching "storage-provisioner"
I1017 19:23:24.217851   13584 logs.go:123] Gathering logs for etcd [b41b269d7bdc] ...
I1017 19:23:24.217851   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b41b269d7bdc"
I1017 19:23:24.270364   13584 logs.go:123] Gathering logs for kube-scheduler [dfb3e3be7dd3] ...
I1017 19:23:24.270364   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dfb3e3be7dd3"
I1017 19:23:24.385169   13584 logs.go:123] Gathering logs for Docker ...
I1017 19:23:24.385169   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I1017 19:23:24.435364   13584 logs.go:123] Gathering logs for kubelet ...
I1017 19:23:24.435364   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I1017 19:23:24.584264   13584 logs.go:123] Gathering logs for kube-apiserver [69ea2c5418d3] ...
I1017 19:23:24.584264   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 69ea2c5418d3"
I1017 19:23:24.631785   13584 logs.go:123] Gathering logs for etcd [42588bc5d0bd] ...
I1017 19:23:24.631785   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 42588bc5d0bd"
I1017 19:23:24.678754   13584 logs.go:123] Gathering logs for kube-scheduler [81c22dae6e21] ...
I1017 19:23:24.678754   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 81c22dae6e21"
I1017 19:23:24.807679   13584 logs.go:123] Gathering logs for kube-controller-manager [872971b21a7a] ...
I1017 19:23:24.807679   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 872971b21a7a"
I1017 19:23:24.846666   13584 logs.go:123] Gathering logs for container status ...
I1017 19:23:24.846666   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I1017 19:23:24.921323   13584 logs.go:123] Gathering logs for dmesg ...
I1017 19:23:24.921323   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I1017 19:23:24.949563   13584 logs.go:123] Gathering logs for describe nodes ...
I1017 19:23:24.949563   13584 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W1017 19:23:25.094704   13584 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:23:25.080349    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.082950    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.085151    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.088225    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.090466    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E1017 17:23:25.080349    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.082950    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.085151    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.088225    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:23:25.090466    9389 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I1017 19:23:25.094704   13584 logs.go:123] Gathering logs for coredns [2c99b8895a55] ...
I1017 19:23:25.094704   13584 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2c99b8895a55"
I1017 19:23:27.682637   13584 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:57534/healthz ...
I1017 19:23:27.689052   13584 api_server.go:269] stopped: https://127.0.0.1:57534/healthz: Get "https://127.0.0.1:57534/healthz": EOF
I1017 19:23:27.690135   13584 out.go:201] 
W1017 19:23:27.691820   13584 out.go:270] âŒ  Exiting due to GUEST_START: failed to start node: wait 6m0s for node: wait for healthy API server: apiserver healthz never reported healthy: context deadline exceeded
W1017 19:23:27.693205   13584 out.go:270] 
W1017 19:23:27.696633   13584 out.go:293] [31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®[0m
[31mâ”‚[0m                                                                                           [31mâ”‚[0m
[31mâ”‚[0m    ðŸ˜¿  If the above advice does not help, please let us know:                             [31mâ”‚[0m
[31mâ”‚[0m    ðŸ‘‰  https://github.com/kubernetes/minikube/issues/new/choose                           [31mâ”‚[0m
[31mâ”‚[0m                                                                                           [31mâ”‚[0m
[31mâ”‚[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31mâ”‚[0m
[31mâ”‚[0m                                                                                           [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m
I1017 19:23:27.700957   13584 out.go:201] 


==> Docker <==
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.151426196Z" level=info msg="Loading containers: start."
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.473012544Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563264860Z" level=warning msg="error locating sandbox id 89e3257866ce04835548a4ee2b53be41b33249787442ea9a98406707551573f4: sandbox 89e3257866ce04835548a4ee2b53be41b33249787442ea9a98406707551573f4 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563352276Z" level=warning msg="error locating sandbox id 6d081cd765e352cbfabdc6576b1f6e435fb26469cb98668de09c8cf55a8dfc2e: sandbox 6d081cd765e352cbfabdc6576b1f6e435fb26469cb98668de09c8cf55a8dfc2e not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563386482Z" level=warning msg="error locating sandbox id 32833ccd66ba8e9ee44ffe87456e23609f9adb866ad9c338d183ac07547b7f99: sandbox 32833ccd66ba8e9ee44ffe87456e23609f9adb866ad9c338d183ac07547b7f99 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563403385Z" level=warning msg="error locating sandbox id 705b51a48fc663964ef1611105bba82a8d3fcc03a497a9688e5c006416d692b9: sandbox 705b51a48fc663964ef1611105bba82a8d3fcc03a497a9688e5c006416d692b9 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563420488Z" level=warning msg="error locating sandbox id ff9781b45274fd4b098afac3de8101e8e3bb80c1bac73a03b5b48417b39b0bcd: sandbox ff9781b45274fd4b098afac3de8101e8e3bb80c1bac73a03b5b48417b39b0bcd not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563436891Z" level=warning msg="error locating sandbox id a4e11b9b561d3f2fcffc7f1f52828256d780feb907fec2196c9100a28a175217: sandbox a4e11b9b561d3f2fcffc7f1f52828256d780feb907fec2196c9100a28a175217 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563457095Z" level=warning msg="error locating sandbox id 3c85fabc60e979ad8765daf7d77cc7d1e6aa0a32730d48e016fd2d3179534165: sandbox 3c85fabc60e979ad8765daf7d77cc7d1e6aa0a32730d48e016fd2d3179534165 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563473698Z" level=warning msg="error locating sandbox id 7c5a4594906891b6cf3195b6e1aea0caf6dec54da993eda785840820c2c3c3cf: sandbox 7c5a4594906891b6cf3195b6e1aea0caf6dec54da993eda785840820c2c3c3cf not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563489701Z" level=warning msg="error locating sandbox id 2ee531c8e456743f4fa8f80ced3eaf9b3b4d3461ddb52d693d8f487e4bf0c0d9: sandbox 2ee531c8e456743f4fa8f80ced3eaf9b3b4d3461ddb52d693d8f487e4bf0c0d9 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563505304Z" level=warning msg="error locating sandbox id 3238f0d14d8d7d0c38ec06c022e52ea4f54a5abfa7b26944c4003568559c64a2: sandbox 3238f0d14d8d7d0c38ec06c022e52ea4f54a5abfa7b26944c4003568559c64a2 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.563520107Z" level=warning msg="error locating sandbox id 73564b35063ceff22fa9cbe102b6d4dc30cade3f7dfdccce688869e49f67c818: sandbox 73564b35063ceff22fa9cbe102b6d4dc30cade3f7dfdccce688869e49f67c818 not found"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.564106114Z" level=info msg="Loading containers: done."
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.592062830Z" level=warning msg="WARNING: No blkio throttle.read_bps_device support"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.592124141Z" level=warning msg="WARNING: No blkio throttle.write_bps_device support"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.592145345Z" level=warning msg="WARNING: No blkio throttle.read_iops_device support"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.592164148Z" level=warning msg="WARNING: No blkio throttle.write_iops_device support"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.592343681Z" level=info msg="Docker daemon" commit=3ab5c7d containerd-snapshotter=false storage-driver=overlay2 version=27.2.0
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.592420995Z" level=info msg="Daemon has completed initialization"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.664961470Z" level=info msg="API listen on /var/run/docker.sock"
Oct 17 17:19:16 minikube dockerd[1008]: time="2024-10-17T17:19:16.665021581Z" level=info msg="API listen on [::]:2376"
Oct 17 17:19:16 minikube systemd[1]: Started Docker Application Container Engine.
Oct 17 17:19:17 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Starting cri-dockerd dev (HEAD)"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Start docker client with request timeout 0s"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Hairpin mode is set to hairpin-veth"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Loaded network plugin cni"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Docker cri networking managed by network plugin cni"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Setting cgroupDriver cgroupfs"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Oct 17 17:19:18 minikube cri-dockerd[1298]: time="2024-10-17T17:19:18Z" level=info msg="Start cri-dockerd grpc backend"
Oct 17 17:19:18 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Oct 17 17:19:21 minikube cri-dockerd[1298]: time="2024-10-17T17:19:21Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"back-deployment-v1-744c9dccdf-g2c8f_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"cbcf6ad5639300900778457debbbc582e0e997828fd17eec59c3a08241bfd05a\""
Oct 17 17:19:21 minikube cri-dockerd[1298]: time="2024-10-17T17:19:21Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"hello-deployment-v1-6dc67886b-lw7h5_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"34eb24e2e8b9be8901bf49b80d4c3f944d8bbabf967b430764982c1eec57aa00\""
Oct 17 17:19:21 minikube cri-dockerd[1298]: time="2024-10-17T17:19:21Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"back-deployment-v1-744c9dccdf-qgvt8_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"62318720869adaa91da0fdc2493bec96da6bb6a0e412439c7433ddf83c560bac\""
Oct 17 17:19:21 minikube cri-dockerd[1298]: time="2024-10-17T17:19:21Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"coredns-6f6b679f8f-6mfql_kube-system\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"b799188a185e34f2d661cd9db7e1775bc75bf9925e29ba0867184cfe1adb3d41\""
Oct 17 17:19:22 minikube cri-dockerd[1298]: time="2024-10-17T17:19:22Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"hello-deployment-v1-6dc67886b-74rnl_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"059536c1003ffffe4c8aa2ba9dc990ee2db1a86db3a40080652902a468f3cc8a\""
Oct 17 17:19:22 minikube cri-dockerd[1298]: time="2024-10-17T17:19:22Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"hello-deployment-v1-6dc67886b-5k2cl_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"48196a42f5ef77cac0bd1e18c76ca6e21fd0afaf927d63204dde6b651c9a65e0\""
Oct 17 17:19:22 minikube cri-dockerd[1298]: time="2024-10-17T17:19:22Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"back-deployment-v1-744c9dccdf-m9tw2_default\": CNI failed to retrieve network namespace path: cannot find network namespace for the terminated container \"3ed9169af476b0937510d9489ef4b7c15b9c5b3fceaf5430f63e0509994f4d79\""
Oct 17 17:19:22 minikube cri-dockerd[1298]: time="2024-10-17T17:19:22Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"e9d9cb0ba52b11db013acc9a40c9ecd2af369faeb3de75aa7d35de0b66e6a31f\". Proceed without further sandbox information."
Oct 17 17:19:22 minikube cri-dockerd[1298]: time="2024-10-17T17:19:22Z" level=error msg="Error deleting pod / from network {docker e9d9cb0ba52b11db013acc9a40c9ecd2af369faeb3de75aa7d35de0b66e6a31f}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Oct 17 17:19:22 minikube cri-dockerd[1298]: time="2024-10-17T17:19:22Z" level=info msg="Both sandbox container and checkpoint could not be found with id \"855377a1ded6265769af568c9c73f8206526d4ffe44d089253c115e5160beb79\". Proceed without further sandbox information."
Oct 17 17:19:22 minikube cri-dockerd[1298]: time="2024-10-17T17:19:22Z" level=error msg="Error deleting pod / from network {docker 855377a1ded6265769af568c9c73f8206526d4ffe44d089253c115e5160beb79}::loopback:: plugin type=\"loopback\" failed (delete): missing network name"
Oct 17 17:19:23 minikube cri-dockerd[1298]: time="2024-10-17T17:19:23Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1acc769264c5989b461ff7463e37ed7a624da1a1b40a9af2da14838e8b1d3e58/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Oct 17 17:19:24 minikube cri-dockerd[1298]: time="2024-10-17T17:19:24Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/ba9cfe9cbd27c82eba4e49612ce39507e9ab71a533fd19fa60f5435ad211e72b/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Oct 17 17:19:25 minikube cri-dockerd[1298]: time="2024-10-17T17:19:25Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/78bfde2b971e384109ab8568f7eafc81ceb11ad32405bfd8cd831ed9c6422068/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Oct 17 17:19:26 minikube dockerd[1008]: time="2024-10-17T17:19:26.516948191Z" level=info msg="ignoring event" container=6dfae3ba59210a3736c1e14056f2b6564d71f095f9749baf6560edd69b7b2179 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:19:27 minikube cri-dockerd[1298]: time="2024-10-17T17:19:27Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/6ec9e0e13201b56ed2e3170b67db0132bf8410990209db34808ed65a7cf429f2/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Oct 17 17:19:38 minikube dockerd[1008]: time="2024-10-17T17:19:38.406060087Z" level=info msg="ignoring event" container=3b039ecd072fcb229ad51830a7fe8aecc9dc7dfca052b82f4301aabe7b95737d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:19:45 minikube dockerd[1008]: time="2024-10-17T17:19:45.031393125Z" level=info msg="ignoring event" container=d892379da323143b653936fd1861d0ca4c0dcf77d9373ced151fd2a650c7e089 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:20:10 minikube dockerd[1008]: time="2024-10-17T17:20:10.306097617Z" level=info msg="ignoring event" container=630b42f6c24d0c1330b741041be819a8b87d917c44d9febe1150202b530bbcb6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:20:17 minikube dockerd[1008]: time="2024-10-17T17:20:17.771677611Z" level=info msg="ignoring event" container=b5485cf82ba8fd4e533d03b0b16872294bd988b4aee5d3c69a6ddfb783707aa1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:20:45 minikube dockerd[1008]: time="2024-10-17T17:20:45.273969889Z" level=info msg="ignoring event" container=668de80183be12fc546cfdd138081f392749ec19cb54690fe4ec0e5fecf1ee46 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:21:12 minikube dockerd[1008]: time="2024-10-17T17:21:12.709937950Z" level=info msg="ignoring event" container=2196b67ad8feb94510c6e0449ddb12db0b2aa23bb10c366705c62011a848ee76 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:21:41 minikube dockerd[1008]: time="2024-10-17T17:21:41.690030770Z" level=info msg="ignoring event" container=950676de58d2f3a573cecc91a2f897de2e8b6cec741dace1a21bef484f61deb9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:22:40 minikube dockerd[1008]: time="2024-10-17T17:22:40.986641775Z" level=info msg="ignoring event" container=69ea2c5418d34fada250572bd9e802e475c6d246bd451d0d8a82b5aa220ec8fb module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Oct 17 17:23:19 minikube dockerd[1008]: time="2024-10-17T17:23:19.298173146Z" level=info msg="ignoring event" container=872971b21a7a3101b67c04b6cb1856d0441734312a6154c076deff95c9d3a193 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"


==> container status <==
CONTAINER           IMAGE               CREATED              STATE               NAME                      ATTEMPT             POD ID              POD
872971b21a7a3       045733566833c       About a minute ago   Exited              kube-controller-manager   12                  ba9cfe9cbd27c       kube-controller-manager-minikube
69ea2c5418d34       604f5db92eaa8       About a minute ago   Exited              kube-apiserver            12                  1acc769264c59       kube-apiserver-minikube
dfb3e3be7dd3e       1766f54c897f0       4 minutes ago        Running             kube-scheduler            2                   6ec9e0e13201b       kube-scheduler-minikube
42588bc5d0bde       2e96e5913fc06       4 minutes ago        Running             etcd                      2                   78bfde2b971e3       etcd-minikube
b41b269d7bdca       2e96e5913fc06       19 minutes ago       Exited              etcd                      1                   b868b21cdfd3c       etcd-minikube
81c22dae6e215       1766f54c897f0       19 minutes ago       Exited              kube-scheduler            1                   029976a582440       kube-scheduler-minikube
95a21b5856f12       7868f10dd8943       51 minutes ago       Exited              frontend-v1               7                   48196a42f5ef7       hello-deployment-v1-6dc67886b-5k2cl
7921e8c581e6d       7868f10dd8943       51 minutes ago       Exited              frontend-v1               7                   059536c1003ff       hello-deployment-v1-6dc67886b-74rnl
5db0f83102919       7868f10dd8943       51 minutes ago       Exited              frontend-v1               7                   34eb24e2e8b9b       hello-deployment-v1-6dc67886b-lw7h5
2c99b8895a555       cbb01a7bd410d       About an hour ago    Exited              coredns                   0                   b799188a185e3       coredns-6f6b679f8f-6mfql


==> coredns [2c99b8895a55] <==
[INFO] 10.244.0.8:55247 - 8852 "A IN penpot-backend. udp 32 false 512" - - 0 2.002007068s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:46479->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.9:56639 - 26214 "A IN penpot-backend. udp 32 false 512" - - 0 2.000713512s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:46127->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.9:56639 - 7268 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.000933638s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:52710->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.7:35311 - 18511 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.001124562s
[INFO] 10.244.0.7:35311 - 25922 "A IN penpot-backend. udp 32 false 512" - - 0 2.001136562s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:50856->192.168.65.254:53: i/o timeout
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:52653->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.8:55247 - 8852 "A IN penpot-backend. udp 32 false 512" - - 0 2.000772919s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:56790->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.8:55247 - 40086 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.002145784s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:33271->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.7:35311 - 25922 "A IN penpot-backend. udp 32 false 512" - - 0 2.001044552s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:35122->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.7:35311 - 18511 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.001214572s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:37898->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.5:33009 - 20552 "AAAA IN penpot-backend.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000468756s
[INFO] 10.244.0.5:33009 - 29009 "A IN penpot-backend.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000659779s
[INFO] 10.244.0.5:57605 - 54558 "AAAA IN penpot-backend.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000300536s
[INFO] 10.244.0.5:57605 - 23065 "A IN penpot-backend.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000377945s
[INFO] 10.244.0.5:38171 - 63242 "AAAA IN penpot-backend.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000223827s
[INFO] 10.244.0.5:38171 - 33044 "A IN penpot-backend.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000302736s
[INFO] 10.244.0.5:41733 - 57855 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.001021612s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:44423->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.5:41733 - 56827 "A IN penpot-backend. udp 32 false 512" - - 0 2.000920399s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:39617->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.5:41733 - 57855 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.001359152s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:38329->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.5:41733 - 56827 "A IN penpot-backend. udp 32 false 512" - - 0 2.00142536s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:53448->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.6:37202 - 57611 "AAAA IN penpot-backend.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000216327s
[INFO] 10.244.0.6:37202 - 26372 "A IN penpot-backend.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.00031734s
[INFO] 10.244.0.6:52334 - 63280 "AAAA IN penpot-backend.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000208026s
[INFO] 10.244.0.6:52334 - 59917 "A IN penpot-backend.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000272934s
[INFO] 10.244.0.6:47207 - 40752 "AAAA IN penpot-backend.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000135517s
[INFO] 10.244.0.6:47207 - 32058 "A IN penpot-backend.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000194424s
[INFO] 10.244.0.6:41437 - 35063 "A IN penpot-backend. udp 32 false 512" - - 0 2.00200635s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:49454->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.6:41437 - 17392 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.002506113s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:49127->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.6:41437 - 17392 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.00119265s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:53815->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.6:41437 - 35063 "A IN penpot-backend. udp 32 false 512" - - 0 2.003513738s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:39588->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.4:59201 - 46049 "A IN penpot-backend.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000183223s
[INFO] 10.244.0.4:59201 - 14060 "AAAA IN penpot-backend.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000320641s
[INFO] 10.244.0.4:42342 - 29208 "AAAA IN penpot-backend.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000166521s
[INFO] 10.244.0.4:42342 - 28188 "A IN penpot-backend.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000088411s
[INFO] 10.244.0.4:60924 - 61991 "AAAA IN penpot-backend.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000138318s
[INFO] 10.244.0.4:60924 - 56097 "A IN penpot-backend.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000101712s
[INFO] 10.244.0.4:34107 - 7964 "A IN penpot-backend. udp 32 false 512" - - 0 2.000540044s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:54271->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.4:34107 - 62224 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.004470623s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:59991->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.4:34107 - 7964 "A IN penpot-backend. udp 32 false 512" - - 0 2.001516882s
[ERROR] plugin/errors: 2 penpot-backend. A: read udp 10.244.0.2:50906->192.168.65.254:53: i/o timeout
[INFO] 10.244.0.4:34107 - 62224 "AAAA IN penpot-backend. udp 32 false 512" - - 0 2.001532385s
[ERROR] plugin/errors: 2 penpot-backend. AAAA: read udp 10.244.0.2:50223->192.168.65.254:53: i/o timeout


==> describe nodes <==
command /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" failed with error: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.31.0/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E1017 17:24:10.412330    9538 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:24:10.417110    9538 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:24:10.420480    9538 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:24:10.423521    9538 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E1017 17:24:10.427347    9538 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?


==> dmesg <==
[Oct17 17:17] MDS CPU bug present and SMT on, data leak possible. See https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/mds.html for more details.
[  +0.000000] MMIO Stale Data CPU bug present and SMT on, data leak possible. See https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/processor_mmio_stale_data.html for more details.
[  +0.000000]  #2 #3
[  +0.021214] PCI: Fatal: No config space access function found
[  +2.750059] PCI: System does not support PCI
[  +0.797128] kvm: already loaded the other module
[  +4.532696] FS-Cache: Duplicate cookie detected
[  +0.042558] FS-Cache: O-cookie c=00000004 [p=00000002 fl=222 nc=0 na=1]
[  +0.004057] FS-Cache: O-cookie d=00000000d7e7f075{9P.session} n=00000000aa3a4111
[  +0.026005] FS-Cache: O-key=[10] '34323934393338313037'
[  +0.000743] FS-Cache: N-cookie c=00000005 [p=00000002 fl=2 nc=0 na=1]
[  +0.001075] FS-Cache: N-cookie d=00000000d7e7f075{9P.session} n=000000006960caee
[  +0.016909] FS-Cache: N-key=[10] '34323934393338313037'
[  +1.872047] WSL (1) ERROR: ConfigApplyWindowsLibPath:2537: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000007]  failed 2
[  +0.285844] WSL (1) WARNING: /usr/share/zoneinfo/Europe/Madrid not found. Is the tzdata package installed?
[  +0.897856] misc dxg: dxgk: dxgglobal_acquire_channel_lock: Failed to acquire global channel lock
[  +6.739101] netlink: 'init': attribute type 4 has an invalid length.
[Oct17 17:19] tmpfs: Unknown parameter 'noswap'


==> etcd [42588bc5d0bd] <==
{"level":"warn","ts":"2024-10-17T17:19:26.264936Z","caller":"embed/config.go:687","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2024-10-17T17:19:26.265189Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2024-10-17T17:19:26.265368Z","caller":"etcdmain/etcd.go:116","msg":"server has been already initialized","data-dir":"/var/lib/minikube/etcd","dir-type":"member"}
{"level":"warn","ts":"2024-10-17T17:19:26.265424Z","caller":"embed/config.go:687","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2024-10-17T17:19:26.265445Z","caller":"embed/etcd.go:128","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-10-17T17:19:26.265515Z","caller":"embed/etcd.go:496","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-10-17T17:19:26.274448Z","caller":"embed/etcd.go:136","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2024-10-17T17:19:26.275045Z","caller":"embed/etcd.go:310","msg":"starting an etcd server","etcd-version":"3.5.15","git-sha":"9a5533382","go-version":"go1.21.12","go-os":"linux","go-arch":"amd64","max-cpu-set":4,"max-cpu-available":4,"member-initialized":true,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2024-10-17T17:19:26.308918Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"32.772653ms"}
{"level":"info","ts":"2024-10-17T17:19:26.315446Z","caller":"etcdserver/server.go:532","msg":"No snapshot found. Recovering WAL from scratch!"}
{"level":"info","ts":"2024-10-17T17:19:26.320712Z","caller":"etcdserver/raft.go:530","msg":"restarting local member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","commit-index":6}
{"level":"info","ts":"2024-10-17T17:19:26.320898Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2024-10-17T17:19:26.322811Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 3"}
{"level":"info","ts":"2024-10-17T17:19:26.322842Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 3, commit: 6, applied: 0, lastindex: 6, lastterm: 3]"}
{"level":"warn","ts":"2024-10-17T17:19:26.327112Z","caller":"auth/store.go:1241","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2024-10-17T17:19:26.341778Z","caller":"mvcc/kvstore.go:418","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2024-10-17T17:19:26.345592Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2024-10-17T17:19:26.351258Z","caller":"etcdserver/corrupt.go:96","msg":"starting initial corruption check","local-member-id":"aec36adc501070cc","timeout":"7s"}
{"level":"info","ts":"2024-10-17T17:19:26.351411Z","caller":"etcdserver/corrupt.go:177","msg":"initial corruption checking passed; no corruption","local-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2024-10-17T17:19:26.351484Z","caller":"etcdserver/server.go:867","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.15","cluster-version":"to_be_decided"}
{"level":"info","ts":"2024-10-17T17:19:26.351799Z","caller":"etcdserver/server.go:767","msg":"starting initial election tick advance","election-ticks":10}
{"level":"info","ts":"2024-10-17T17:19:26.352095Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2024-10-17T17:19:26.352171Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2024-10-17T17:19:26.352188Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2024-10-17T17:19:26.357345Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2024-10-17T17:19:26.352776Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-10-17T17:19:26.357712Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-10-17T17:19:26.357940Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2024-10-17T17:19:26.358066Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2024-10-17T17:19:26.368126Z","caller":"embed/etcd.go:728","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-10-17T17:19:26.368536Z","caller":"embed/etcd.go:279","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2024-10-17T17:19:26.368591Z","caller":"embed/etcd.go:870","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2024-10-17T17:19:26.371372Z","caller":"embed/etcd.go:599","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-10-17T17:19:26.371460Z","caller":"embed/etcd.go:571","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-10-17T17:19:28.023948Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 3"}
{"level":"info","ts":"2024-10-17T17:19:28.024048Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 3"}
{"level":"info","ts":"2024-10-17T17:19:28.024115Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 3"}
{"level":"info","ts":"2024-10-17T17:19:28.024139Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 4"}
{"level":"info","ts":"2024-10-17T17:19:28.024152Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 4"}
{"level":"info","ts":"2024-10-17T17:19:28.024164Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 4"}
{"level":"info","ts":"2024-10-17T17:19:28.024215Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 4"}
{"level":"info","ts":"2024-10-17T17:19:28.037135Z","caller":"etcdserver/server.go:2118","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2024-10-17T17:19:28.037580Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-10-17T17:19:28.038166Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-10-17T17:19:28.038668Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2024-10-17T17:19:28.038704Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2024-10-17T17:19:28.042023Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-10-17T17:19:28.043337Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"192.168.49.2:2379"}
{"level":"info","ts":"2024-10-17T17:19:28.044370Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-10-17T17:19:28.048324Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"info","ts":"2024-10-17T17:21:23.830093Z","caller":"traceutil/trace.go:171","msg":"trace[1441025107] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:1; }","duration":"118.334923ms","start":"2024-10-17T17:21:23.674155Z","end":"2024-10-17T17:21:23.792489Z","steps":["trace[1441025107] 'agreement among raft nodes before linearized reading'  (duration: 118.316521ms)"],"step_count":1}


==> etcd [b41b269d7bdc] <==
{"level":"warn","ts":"2024-10-17T17:04:49.307453Z","caller":"embed/config.go:687","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2024-10-17T17:04:49.310251Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2024-10-17T17:04:49.313526Z","caller":"etcdmain/etcd.go:116","msg":"server has been already initialized","data-dir":"/var/lib/minikube/etcd","dir-type":"member"}
{"level":"warn","ts":"2024-10-17T17:04:49.313712Z","caller":"embed/config.go:687","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2024-10-17T17:04:49.313807Z","caller":"embed/etcd.go:128","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-10-17T17:04:49.325225Z","caller":"embed/etcd.go:496","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-10-17T17:04:49.338610Z","caller":"embed/etcd.go:136","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2024-10-17T17:04:49.340155Z","caller":"embed/etcd.go:310","msg":"starting an etcd server","etcd-version":"3.5.15","git-sha":"9a5533382","go-version":"go1.21.12","go-os":"linux","go-arch":"amd64","max-cpu-set":4,"max-cpu-available":4,"member-initialized":true,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"","initial-cluster-state":"new","initial-cluster-token":"","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2024-10-17T17:04:49.381352Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"40.106001ms"}
{"level":"info","ts":"2024-10-17T17:04:49.435229Z","caller":"etcdserver/server.go:532","msg":"No snapshot found. Recovering WAL from scratch!"}
{"level":"info","ts":"2024-10-17T17:04:49.454537Z","caller":"etcdserver/raft.go:530","msg":"restarting local member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","commit-index":4}
{"level":"info","ts":"2024-10-17T17:04:49.456006Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2024-10-17T17:04:49.461495Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 2"}
{"level":"info","ts":"2024-10-17T17:04:49.461679Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 2, commit: 4, applied: 0, lastindex: 4, lastterm: 2]"}
{"level":"warn","ts":"2024-10-17T17:04:49.473678Z","caller":"auth/store.go:1241","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2024-10-17T17:04:49.519039Z","caller":"mvcc/kvstore.go:418","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2024-10-17T17:04:49.524546Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2024-10-17T17:04:49.539938Z","caller":"etcdserver/corrupt.go:96","msg":"starting initial corruption check","local-member-id":"aec36adc501070cc","timeout":"7s"}
{"level":"info","ts":"2024-10-17T17:04:49.549347Z","caller":"etcdserver/corrupt.go:177","msg":"initial corruption checking passed; no corruption","local-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2024-10-17T17:04:49.549524Z","caller":"etcdserver/server.go:867","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.15","cluster-version":"to_be_decided"}
{"level":"info","ts":"2024-10-17T17:04:49.551768Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-10-17T17:04:49.567720Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2024-10-17T17:04:49.567922Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2024-10-17T17:04:49.567949Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2024-10-17T17:04:49.568084Z","caller":"etcdserver/server.go:767","msg":"starting initial election tick advance","election-ticks":10}
{"level":"info","ts":"2024-10-17T17:04:49.569370Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2024-10-17T17:04:49.569947Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2024-10-17T17:04:49.571537Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2024-10-17T17:04:49.571742Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2024-10-17T17:04:49.575026Z","caller":"embed/etcd.go:728","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2024-10-17T17:04:49.575318Z","caller":"embed/etcd.go:599","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-10-17T17:04:49.575611Z","caller":"embed/etcd.go:571","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2024-10-17T17:04:49.580060Z","caller":"embed/etcd.go:279","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2024-10-17T17:04:49.580207Z","caller":"embed/etcd.go:870","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2024-10-17T17:04:50.768987Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 2"}
{"level":"info","ts":"2024-10-17T17:04:50.769092Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 2"}
{"level":"info","ts":"2024-10-17T17:04:50.769150Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2024-10-17T17:04:50.769176Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 3"}
{"level":"info","ts":"2024-10-17T17:04:50.769192Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 3"}
{"level":"info","ts":"2024-10-17T17:04:50.769286Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 3"}
{"level":"info","ts":"2024-10-17T17:04:50.769308Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 3"}
{"level":"info","ts":"2024-10-17T17:04:50.784350Z","caller":"etcdserver/server.go:2118","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2024-10-17T17:04:50.784674Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-10-17T17:04:50.784921Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2024-10-17T17:04:50.784955Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2024-10-17T17:04:50.784978Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2024-10-17T17:04:50.789193Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-10-17T17:04:50.791666Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"info","ts":"2024-10-17T17:04:50.793433Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2024-10-17T17:04:50.795792Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"192.168.49.2:2379"}


==> kernel <==
 17:24:10 up 7 min,  0 users,  load average: 0.27, 0.72, 0.44
Linux minikube 5.15.153.1-microsoft-standard-WSL2 #1 SMP Fri Mar 29 23:14:13 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.4 LTS"


==> kube-apiserver [69ea2c5418d3] <==
I1017 17:22:40.960230       1 options.go:228] external host was not specified, using 192.168.49.2
E1017 17:22:40.961135       1 run.go:72] "command failed" err="authorization-mode \"RBAC*\" is not a valid mode"


==> kube-controller-manager [872971b21a7a] <==
I1017 17:23:08.783660       1 serving.go:386] Generated self-signed cert in-memory
I1017 17:23:09.194383       1 controllermanager.go:197] "Starting" version="v1.31.0"
I1017 17:23:09.194422       1 controllermanager.go:199] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1017 17:23:09.197484       1 dynamic_cafile_content.go:160] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I1017 17:23:09.197746       1 dynamic_cafile_content.go:160] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I1017 17:23:09.197843       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I1017 17:23:09.197923       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
E1017 17:23:19.203998       1 controllermanager.go:242] "Error building controller context" err="failed to wait for apiserver being healthy: timed out waiting for the condition: failed to get apiserver /healthz status: Get \"https://192.168.49.2:8443/healthz\": dial tcp 192.168.49.2:8443: connect: connection refused"


==> kube-scheduler [81c22dae6e21] <==
W1017 17:11:03.609068       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:03.609408       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:06.552049       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:06.552200       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:07.122655       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:07.123634       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:10.295494       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:10.295624       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:12.092893       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:12.093072       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:17.792957       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:17.793415       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get \"https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:19.275067       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:19.275602       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:19.382741       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:19.382859       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:19.746183       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:19.746355       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:23.582163       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:23.582313       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:27.179187       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:27.179321       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:30.283734       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:30.283934       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:34.535141       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:34.535542       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:35.081361       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:35.081671       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:46.189396       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:46.189471       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:49.951412       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:49.951588       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:50.399439       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:50.400387       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:51.229988       1 reflector.go:561] runtime/asm_amd64.s:1695: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:51.230077       1 reflector.go:158] "Unhandled Error" err="runtime/asm_amd64.s:1695: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:52.957035       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:52.957129       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get \"https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:57.436896       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:57.436998       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:11:59.121757       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:11:59.122248       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get \"https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:02.409162       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:02.409482       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:08.305278       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:08.305369       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:15.939390       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:15.939693       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:17.134361       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:17.134577       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:20.621850       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:20.622075       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:21.650507       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:21.650639       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:23.090615       1 reflector.go:561] runtime/asm_amd64.s:1695: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:23.090761       1 reflector.go:158] "Unhandled Error" err="runtime/asm_amd64.s:1695: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:23.431019       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:23.431207       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:12:26.349867       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:12:26.349993       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"


==> kube-scheduler [dfb3e3be7dd3] <==
W1017 17:22:29.708796       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:29.708933       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get \"https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:31.904607       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:31.904769       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:39.546137       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:39.546266       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:47.139477       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:47.139663       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:48.331510       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:48.331654       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:48.408701       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:48.408782       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:57.999202       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:57.999439       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:58.478614       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:58.478732       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:59.119207       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:59.119455       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:22:59.474116       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:22:59.474235       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:01.373209       1 reflector.go:561] runtime/asm_amd64.s:1695: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:01.373344       1 reflector.go:158] "Unhandled Error" err="runtime/asm_amd64.s:1695: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:04.528954       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:04.529062       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:04.903613       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:04.903731       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get \"https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:14.365551       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:14.365904       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:16.763389       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:16.763511       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:17.501682       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:17.501794       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:19.679105       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:19.679616       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: Get \"https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:23.979962       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:23.980059       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get \"https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:26.836561       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:26.837063       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get \"https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:28.528375       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:28.529741       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:35.838441       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:35.838521       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:37.608568       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:37.608678       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get \"https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:41.185260       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:41.185370       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get \"https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:44.604227       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:44.604300       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get \"https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:50.267895       1 reflector.go:561] runtime/asm_amd64.s:1695: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:50.268170       1 reflector.go:158] "Unhandled Error" err="runtime/asm_amd64.s:1695: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%3Dextension-apiserver-authentication&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:50.700691       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:50.700846       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Pod: failed to list *v1.Pod: Get \"https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%21%3DSucceeded%2Cstatus.phase%21%3DFailed&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:52.909187       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:52.909302       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:55.183167       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:55.183291       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:23:58.260798       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:23:58.260911       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get \"https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
W1017 17:24:04.430785       1 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E1017 17:24:04.431146       1 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get \"https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"


==> kubelet <==
Oct 17 17:23:19 minikube kubelet[1476]: I1017 17:23:19.820586    1476 scope.go:117] "RemoveContainer" containerID="950676de58d2f3a573cecc91a2f897de2e8b6cec741dace1a21bef484f61deb9"
Oct 17 17:23:19 minikube kubelet[1476]: I1017 17:23:19.823050    1476 scope.go:117] "RemoveContainer" containerID="872971b21a7a3101b67c04b6cb1856d0441734312a6154c076deff95c9d3a193"
Oct 17 17:23:19 minikube kubelet[1476]: E1017 17:23:19.823330    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(40f5f661ab65f2e4bfe41ac2993c01de)\"" pod="kube-system/kube-controller-manager-minikube" podUID="40f5f661ab65f2e4bfe41ac2993c01de"
Oct 17 17:23:20 minikube kubelet[1476]: I1017 17:23:20.844888    1476 scope.go:117] "RemoveContainer" containerID="872971b21a7a3101b67c04b6cb1856d0441734312a6154c076deff95c9d3a193"
Oct 17 17:23:20 minikube kubelet[1476]: E1017 17:23:20.845592    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(40f5f661ab65f2e4bfe41ac2993c01de)\"" pod="kube-system/kube-controller-manager-minikube" podUID="40f5f661ab65f2e4bfe41ac2993c01de"
Oct 17 17:23:21 minikube kubelet[1476]: E1017 17:23:21.794231    1476 eviction_manager.go:285] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Oct 17 17:23:23 minikube kubelet[1476]: W1017 17:23:23.004203    1476 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.CSIDriver: Get "https://control-plane.minikube.internal:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
Oct 17 17:23:23 minikube kubelet[1476]: E1017 17:23:23.004314    1476 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get \"https://control-plane.minikube.internal:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
Oct 17 17:23:24 minikube kubelet[1476]: E1017 17:23:24.219032    1476 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.17ff4d1b47884307  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:CgroupV1,Message:Cgroup v1 support is in maintenance mode, please migrate to Cgroup v2.,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,LastTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Oct 17 17:23:24 minikube kubelet[1476]: I1017 17:23:24.583240    1476 scope.go:117] "RemoveContainer" containerID="69ea2c5418d34fada250572bd9e802e475c6d246bd451d0d8a82b5aa220ec8fb"
Oct 17 17:23:24 minikube kubelet[1476]: E1017 17:23:24.583589    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(295566d7f6b8c1e066f1f17b616ba43e)\"" pod="kube-system/kube-apiserver-minikube" podUID="295566d7f6b8c1e066f1f17b616ba43e"
Oct 17 17:23:25 minikube kubelet[1476]: E1017 17:23:25.751830    1476 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Oct 17 17:23:25 minikube kubelet[1476]: I1017 17:23:25.805668    1476 kubelet_node_status.go:72] "Attempting to register node" node="minikube"
Oct 17 17:23:25 minikube kubelet[1476]: E1017 17:23:25.807986    1476 kubelet_node_status.go:95] "Unable to register node with API server" err="Post \"https://control-plane.minikube.internal:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Oct 17 17:23:26 minikube kubelet[1476]: I1017 17:23:26.280650    1476 scope.go:117] "RemoveContainer" containerID="872971b21a7a3101b67c04b6cb1856d0441734312a6154c076deff95c9d3a193"
Oct 17 17:23:26 minikube kubelet[1476]: E1017 17:23:26.282393    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(40f5f661ab65f2e4bfe41ac2993c01de)\"" pod="kube-system/kube-controller-manager-minikube" podUID="40f5f661ab65f2e4bfe41ac2993c01de"
Oct 17 17:23:31 minikube kubelet[1476]: W1017 17:23:31.100437    1476 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.RuntimeClass: Get "https://control-plane.minikube.internal:8443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
Oct 17 17:23:31 minikube kubelet[1476]: E1017 17:23:31.100644    1476 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get \"https://control-plane.minikube.internal:8443/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
Oct 17 17:23:31 minikube kubelet[1476]: E1017 17:23:31.790419    1476 eviction_manager.go:285] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Oct 17 17:23:32 minikube kubelet[1476]: E1017 17:23:32.749871    1476 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Oct 17 17:23:32 minikube kubelet[1476]: I1017 17:23:32.805353    1476 kubelet_node_status.go:72] "Attempting to register node" node="minikube"
Oct 17 17:23:32 minikube kubelet[1476]: E1017 17:23:32.807937    1476 kubelet_node_status.go:95] "Unable to register node with API server" err="Post \"https://control-plane.minikube.internal:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Oct 17 17:23:34 minikube kubelet[1476]: E1017 17:23:34.215246    1476 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.17ff4d1b47884307  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:CgroupV1,Message:Cgroup v1 support is in maintenance mode, please migrate to Cgroup v2.,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,LastTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Oct 17 17:23:35 minikube kubelet[1476]: I1017 17:23:35.565433    1476 scope.go:117] "RemoveContainer" containerID="69ea2c5418d34fada250572bd9e802e475c6d246bd451d0d8a82b5aa220ec8fb"
Oct 17 17:23:35 minikube kubelet[1476]: E1017 17:23:35.565881    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(295566d7f6b8c1e066f1f17b616ba43e)\"" pod="kube-system/kube-apiserver-minikube" podUID="295566d7f6b8c1e066f1f17b616ba43e"
Oct 17 17:23:37 minikube kubelet[1476]: W1017 17:23:37.069544    1476 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%3Dminikube&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
Oct 17 17:23:37 minikube kubelet[1476]: E1017 17:23:37.069680    1476 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Node: failed to list *v1.Node: Get \"https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%3Dminikube&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
Oct 17 17:23:37 minikube kubelet[1476]: I1017 17:23:37.565357    1476 scope.go:117] "RemoveContainer" containerID="872971b21a7a3101b67c04b6cb1856d0441734312a6154c076deff95c9d3a193"
Oct 17 17:23:37 minikube kubelet[1476]: E1017 17:23:37.565710    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(40f5f661ab65f2e4bfe41ac2993c01de)\"" pod="kube-system/kube-controller-manager-minikube" podUID="40f5f661ab65f2e4bfe41ac2993c01de"
Oct 17 17:23:39 minikube kubelet[1476]: E1017 17:23:39.752371    1476 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Oct 17 17:23:39 minikube kubelet[1476]: I1017 17:23:39.810231    1476 kubelet_node_status.go:72] "Attempting to register node" node="minikube"
Oct 17 17:23:39 minikube kubelet[1476]: E1017 17:23:39.811029    1476 kubelet_node_status.go:95] "Unable to register node with API server" err="Post \"https://control-plane.minikube.internal:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Oct 17 17:23:41 minikube kubelet[1476]: E1017 17:23:41.791110    1476 eviction_manager.go:285] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Oct 17 17:23:44 minikube kubelet[1476]: W1017 17:23:44.116319    1476 reflector.go:561] k8s.io/client-go/informers/factory.go:160: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?fieldSelector=spec.clusterIP%21%3DNone&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
Oct 17 17:23:44 minikube kubelet[1476]: E1017 17:23:44.116437    1476 reflector.go:158] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.Service: failed to list *v1.Service: Get \"https://control-plane.minikube.internal:8443/api/v1/services?fieldSelector=spec.clusterIP%21%3DNone&limit=500&resourceVersion=0\": dial tcp 192.168.49.2:8443: connect: connection refused" logger="UnhandledError"
Oct 17 17:23:44 minikube kubelet[1476]: E1017 17:23:44.216640    1476 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.17ff4d1b47884307  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:CgroupV1,Message:Cgroup v1 support is in maintenance mode, please migrate to Cgroup v2.,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,LastTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Oct 17 17:23:46 minikube kubelet[1476]: E1017 17:23:46.754177    1476 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Oct 17 17:23:46 minikube kubelet[1476]: I1017 17:23:46.814691    1476 kubelet_node_status.go:72] "Attempting to register node" node="minikube"
Oct 17 17:23:46 minikube kubelet[1476]: E1017 17:23:46.815318    1476 kubelet_node_status.go:95] "Unable to register node with API server" err="Post \"https://control-plane.minikube.internal:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Oct 17 17:23:50 minikube kubelet[1476]: I1017 17:23:50.566356    1476 scope.go:117] "RemoveContainer" containerID="69ea2c5418d34fada250572bd9e802e475c6d246bd451d0d8a82b5aa220ec8fb"
Oct 17 17:23:50 minikube kubelet[1476]: E1017 17:23:50.566839    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(295566d7f6b8c1e066f1f17b616ba43e)\"" pod="kube-system/kube-apiserver-minikube" podUID="295566d7f6b8c1e066f1f17b616ba43e"
Oct 17 17:23:51 minikube kubelet[1476]: I1017 17:23:51.567799    1476 scope.go:117] "RemoveContainer" containerID="872971b21a7a3101b67c04b6cb1856d0441734312a6154c076deff95c9d3a193"
Oct 17 17:23:51 minikube kubelet[1476]: E1017 17:23:51.568161    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(40f5f661ab65f2e4bfe41ac2993c01de)\"" pod="kube-system/kube-controller-manager-minikube" podUID="40f5f661ab65f2e4bfe41ac2993c01de"
Oct 17 17:23:51 minikube kubelet[1476]: E1017 17:23:51.792104    1476 eviction_manager.go:285] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Oct 17 17:23:53 minikube kubelet[1476]: E1017 17:23:53.756248    1476 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Oct 17 17:23:53 minikube kubelet[1476]: I1017 17:23:53.817988    1476 kubelet_node_status.go:72] "Attempting to register node" node="minikube"
Oct 17 17:23:53 minikube kubelet[1476]: E1017 17:23:53.818686    1476 kubelet_node_status.go:95] "Unable to register node with API server" err="Post \"https://control-plane.minikube.internal:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Oct 17 17:23:54 minikube kubelet[1476]: E1017 17:23:54.218324    1476 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.17ff4d1b47884307  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:CgroupV1,Message:Cgroup v1 support is in maintenance mode, please migrate to Cgroup v2.,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,LastTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Oct 17 17:24:00 minikube kubelet[1476]: E1017 17:24:00.753218    1476 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Oct 17 17:24:00 minikube kubelet[1476]: I1017 17:24:00.819398    1476 kubelet_node_status.go:72] "Attempting to register node" node="minikube"
Oct 17 17:24:00 minikube kubelet[1476]: E1017 17:24:00.821069    1476 kubelet_node_status.go:95] "Unable to register node with API server" err="Post \"https://control-plane.minikube.internal:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"
Oct 17 17:24:01 minikube kubelet[1476]: E1017 17:24:01.789502    1476 eviction_manager.go:285] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"minikube\" not found"
Oct 17 17:24:03 minikube kubelet[1476]: I1017 17:24:03.565502    1476 scope.go:117] "RemoveContainer" containerID="69ea2c5418d34fada250572bd9e802e475c6d246bd451d0d8a82b5aa220ec8fb"
Oct 17 17:24:03 minikube kubelet[1476]: E1017 17:24:03.566436    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-apiserver\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-apiserver pod=kube-apiserver-minikube_kube-system(295566d7f6b8c1e066f1f17b616ba43e)\"" pod="kube-system/kube-apiserver-minikube" podUID="295566d7f6b8c1e066f1f17b616ba43e"
Oct 17 17:24:04 minikube kubelet[1476]: E1017 17:24:04.215374    1476 event.go:368] "Unable to write event (may retry after sleeping)" err="Post \"https://control-plane.minikube.internal:8443/api/v1/namespaces/default/events\": dial tcp 192.168.49.2:8443: connect: connection refused" event="&Event{ObjectMeta:{minikube.17ff4d1b47884307  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Node,Namespace:,Name:minikube,UID:minikube,APIVersion:,ResourceVersion:,FieldPath:,},Reason:CgroupV1,Message:Cgroup v1 support is in maintenance mode, please migrate to Cgroup v2.,Source:EventSource{Component:kubelet,Host:minikube,},FirstTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,LastTimestamp:2024-10-17 17:19:21.493127943 +0000 UTC m=+0.690712311,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kubelet,ReportingInstance:minikube,}"
Oct 17 17:24:06 minikube kubelet[1476]: I1017 17:24:06.561799    1476 scope.go:117] "RemoveContainer" containerID="872971b21a7a3101b67c04b6cb1856d0441734312a6154c076deff95c9d3a193"
Oct 17 17:24:06 minikube kubelet[1476]: E1017 17:24:06.562206    1476 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-controller-manager\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-controller-manager pod=kube-controller-manager-minikube_kube-system(40f5f661ab65f2e4bfe41ac2993c01de)\"" pod="kube-system/kube-controller-manager-minikube" podUID="40f5f661ab65f2e4bfe41ac2993c01de"
Oct 17 17:24:07 minikube kubelet[1476]: E1017 17:24:07.755857    1476 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": dial tcp 192.168.49.2:8443: connect: connection refused" interval="7s"
Oct 17 17:24:07 minikube kubelet[1476]: I1017 17:24:07.824841    1476 kubelet_node_status.go:72] "Attempting to register node" node="minikube"
Oct 17 17:24:07 minikube kubelet[1476]: E1017 17:24:07.826625    1476 kubelet_node_status.go:95] "Unable to register node with API server" err="Post \"https://control-plane.minikube.internal:8443/api/v1/nodes\": dial tcp 192.168.49.2:8443: connect: connection refused" node="minikube"

